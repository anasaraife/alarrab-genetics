# ===================================================================
# ğŸš€ Ø§Ù„Ø¹Ø±Ù‘Ø§Ø¨ Ù„Ù„Ø¬ÙŠÙ†Ø§Øª V5.2 - ÙˆÙƒÙŠÙ„ Ø°ÙƒÙŠ Ø¨Ø´Ø®ØµÙŠØ© Ù…ØªØ·ÙˆØ±Ø©
# ØªØ·ÙˆÙŠØ± Ø¬Ø°Ø±ÙŠ ÙÙŠ Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù„Ù…ÙŠ
# ===================================================================

import streamlit as st
from itertools import product
import collections
import pandas as pd
import numpy as np
import pickle
import os
import json
from datetime import datetime
from typing import List, Dict, Tuple
import plotly.express as px

# --- Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆÙØ± Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© ---
try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

try:
    import faiss
    from sentence_transformers import SentenceTransformer
    VECTOR_SEARCH_AVAILABLE = True
except ImportError:
    VECTOR_SEARCH_AVAILABLE = False

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø© ---
st.set_page_config(
    layout="wide",
    page_title="Ø§Ù„Ø¹Ø±Ù‘Ø§Ø¨ Ù„Ù„Ø¬ÙŠÙ†Ø§Øª V5.2",
    page_icon="ğŸ§¬",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': None,
        'Report a bug': None,
        'About': """
        # Ø§Ù„Ø¹Ø±Ù‘Ø§Ø¨ Ù„Ù„Ø¬ÙŠÙ†Ø§Øª V5.2
        Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø°ÙƒÙŠØ© Ø§Ù„Ù…ØªØ·ÙˆØ±Ø© - ÙˆÙƒÙŠÙ„ Ø°ÙƒÙŠ Ø¨Ø´Ø®ØµÙŠØ© Ø¹Ù„Ù…ÙŠØ© Ù…Ø­Ø³Ù†Ø©
        """
    }
)

# --- 2. CSS Ù…Ø®ØµØµ Ù„Ù„ÙˆØ§Ø¬Ù‡Ø© ---
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 50%, #f093fb 100%);
        padding: 2rem;
        border-radius: 15px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 8px 32px rgba(0,0,0,0.1);
    }
    
    .metric-card {
        background: white;
        padding: 1.5rem;
        border-radius: 12px;
        box-shadow: 0 4px 12px rgba(0,0,0,0.1);
        border-left: 5px solid #667eea;
        margin-bottom: 1rem;
    }
    
    .info-box {
        background: linear-gradient(135deg, #f0f2f6 0%, #e8f5e8 100%);
        padding: 1.5rem;
        border-radius: 12px;
        border-left: 5px solid #28a745;
        margin: 1rem 0;
    }
    
    .warning-box {
        background: linear-gradient(135deg, #fff3cd 0%, #ffeaa7 100%);
        padding: 1.5rem;
        border-radius: 12px;
        border-left: 5px solid #ffc107;
        margin: 1rem 0;
    }
    
    .calculator-section {
        background: linear-gradient(135deg, #f8f9ff 0%, #e6f3ff 100%);
        padding: 2rem;
        border-radius: 15px;
        border: 1px solid #e0e6ed;
        margin: 1rem 0;
    }
    
    .stTabs [data-baseweb="tab-list"] {
        gap: 12px;
        background: rgba(255,255,255,0.1);
        padding: 8px;
        border-radius: 12px;
    }
    
    .stTabs [data-baseweb="tab"] {
        height: 60px;
        padding: 0 30px;
        border-radius: 8px;
        font-weight: 600;
    }
    
    .trusted-source {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #007bff;
        margin: 0.5rem 0;
    }
    
    .agent-thinking {
        background: linear-gradient(135deg, #e3f2fd 0%, #f3e5f5 100%);
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #2196f3;
        margin: 0.5rem 0;
        font-style: italic;
    }
</style>
""", unsafe_allow_html=True)

# --- 3. Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØ±Ø§Ø«ÙŠØ© ÙˆØ§Ù„Ù…ØµØ§Ø¯Ø± ---
GENE_DATA = {
    'B': {
        'display_name_ar': "Ø§Ù„Ù„ÙˆÙ† Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ", 'type_en': 'sex-linked',
        'alleles': { 'BA': {'name': 'Ø¢Ø´ Ø±ÙŠØ¯'}, '+': {'name': 'Ø£Ø²Ø±Ù‚/Ø£Ø³ÙˆØ¯'}, 'b': {'name': 'Ø¨Ù†ÙŠ'} },
        'dominance': ['BA', '+', 'b']
    },
    'd': {
        'display_name_ar': "Ø§Ù„ØªØ®ÙÙŠÙ", 'type_en': 'sex-linked',
        'alleles': { '+': {'name': 'Ø¹Ø§Ø¯ÙŠ (ØºÙŠØ± Ù…Ø®ÙÙ)'}, 'd': {'name': 'Ù…Ø®ÙÙ'} },
        'dominance': ['+', 'd']
    },
    'e': {
        'display_name_ar': "Ø£Ø­Ù…Ø± Ù…ØªÙ†Ø­ÙŠ", 'type_en': 'autosomal',
        'alleles': { '+': {'name': 'Ø¹Ø§Ø¯ÙŠ (ØºÙŠØ± Ø£Ø­Ù…Ø± Ù…ØªÙ†Ø­ÙŠ)'}, 'e': {'name': 'Ø£Ø­Ù…Ø± Ù…ØªÙ†Ø­ÙŠ'} },
        'dominance': ['+', 'e']
    },
    'C': {
        'display_name_ar': "Ø§Ù„Ù†Ù…Ø·", 'type_en': 'autosomal',
        'alleles': { 'CT': {'name': 'Ù†Ù…Ø· ØªÙŠ (Ù…Ø®Ù…Ù„ÙŠ)'}, 'C': {'name': 'ØªØ´ÙŠÙƒØ±'}, '+': {'name': 'Ø¨Ø§Ø± (Ø´Ø±ÙŠØ·)'}, 'c': {'name': 'Ø¨Ø¯ÙˆÙ† Ø´Ø±ÙŠØ·'} },
        'dominance': ['CT', 'C', '+', 'c']
    },
    'S': {
        'display_name_ar': "Ø§Ù„Ø§Ù†ØªØ´Ø§Ø± (Ø³Ø¨Ø±ÙŠØ¯)", 'type_en': 'autosomal',
        'alleles': { 'S': {'name': 'Ù…Ù†ØªØ´Ø± (Ø³Ø¨Ø±ÙŠØ¯)'}, '+': {'name': 'Ø¹Ø§Ø¯ÙŠ (ØºÙŠØ± Ù…Ù†ØªØ´Ø±)'} },
        'dominance': ['S', '+']
    }
}
GENE_ORDER = list(GENE_DATA.keys())
NAME_TO_SYMBOL_MAP = {
    gene: {info['name']: symbol for symbol, info in data['alleles'].items()}
    for gene, data in GENE_DATA.items()
}

# --- 4. Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¬Ù„Ø³Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø© ---
def initialize_session_state():
    """ØªÙ‡ÙŠØ¦Ø© Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø© Ù…Ø¹ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø´Ø§Ù…Ù„Ø©."""
    defaults = {
        "messages": [],
        "search_history": [],
        "calculation_history": [],
        "conversation_context": [],  # Ø¬Ø¯ÙŠØ¯: Ù„ØªØªØ¨Ø¹ Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
        "agent_memory": {},  # Ø¬Ø¯ÙŠØ¯: Ø°Ø§ÙƒØ±Ø© Ø§Ù„ÙˆÙƒÙŠÙ„
        "user_preferences": {
            "max_results": 10,
            "analysis_depth": "Ù…ØªÙˆØ³Ø·",
            "language_style": "Ø¹Ù„Ù…ÙŠ",
            "include_charts": True,
            "show_trusted_sources": True,
            "conversation_mode": "ØªÙØ§Ø¹Ù„ÙŠ",  # Ø¬Ø¯ÙŠØ¯
            "thinking_visibility": True,  # Ø¬Ø¯ÙŠØ¯
        },
        "session_stats": {
            "queries_count": 0,
            "successful_searches": 0,
            "charts_generated": 0,
            "calculations_performed": 0,
            "sources_referenced": 0,
            "deep_analyses": 0,  # Ø¬Ø¯ÙŠØ¯
        },
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

# --- 5. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… ---
@st.cache_resource(show_spinner="Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©...")
def load_enhanced_resources():
    """ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø´Ø§Ù…Ù„Ø© Ù„Ù„Ø£Ø®Ø·Ø§Ø¡."""
    resources = {"status": "loading"}
    
    if VECTOR_SEARCH_AVAILABLE:
        vector_db_path = "vector_db.pkl"
        if os.path.exists(vector_db_path):
            try:
                with open(vector_db_path, "rb") as f:
                    resources["vector_db"] = pickle.load(f)
                resources["embedder"] = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
                resources["status"] = "ready"
            except Exception as e:
                st.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…ØªØ¬Ù‡Ø§Øª: {e}")
                resources["status"] = "failed"
        else:
            st.warning("Ù…Ù„Ù Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© (vector_db.pkl) ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯.")
            resources["status"] = "no_db"
    else:
        resources["status"] = "vector_search_unavailable"
        
    return resources

@st.cache_resource(show_spinner="Ø¬Ø§Ø±ÙŠ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ...")
def initialize_enhanced_gemini():
    """ØªÙ‡ÙŠØ¦Ø© Ù†Ù…ÙˆØ°Ø¬ Gemini Ù…Ø¹ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ø­Ø³Ù†Ø©."""
    if not GEMINI_AVAILABLE: return None
    api_key = st.secrets.get("GEMINI_API_KEY")
    if not api_key: return None
    
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-flash',
            generation_config={"temperature": 0.2, "max_output_tokens": 6000})  # Ø²ÙŠØ§Ø¯Ø© Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰
        return model
    except Exception as e:
        st.error(f"ÙØ´Ù„ ØªÙ‡ÙŠØ¦Ø© Gemini: {e}")
        return None

# --- 6. Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„ÙˆØ±Ø§Ø«ÙŠ Ø§Ù„Ù…Ø·ÙˆØ± ---
class EnhancedGeneticCalculator:
    def describe_phenotype(self, genotype_dict):
        phenotypes = {gene: "" for gene in GENE_ORDER}
        for gene_name, gt_part in genotype_dict.items():
            alleles = gt_part.replace('â€¢//', '').split('//')
            for dominant_allele in GENE_DATA[gene_name]['dominance']:
                if dominant_allele in alleles:
                    phenotypes[gene_name] = GENE_DATA[gene_name]['alleles'][dominant_allele]['name']
                    break
        
        if 'e//e' in genotype_dict.get('e', ''):
            phenotypes['B'] = 'Ø£Ø­Ù…Ø± Ù…ØªÙ†Ø­ÙŠ'
            phenotypes['C'] = ''
        
        if 'S' in genotype_dict.get('S', ''):
            if 'e//e' not in genotype_dict.get('e', ''):
                phenotypes['C'] = 'Ù…Ù†ØªØ´Ø± (Ø³Ø¨Ø±ÙŠØ¯)'
        
        sex = "Ø£Ù†Ø«Ù‰" if any('â€¢' in genotype_dict.get(g, '') for g, d in GENE_DATA.items() if d['type_en'] == 'sex-linked') else "Ø°ÙƒØ±"
        
        desc_parts = [phenotypes.get('B')]
        if phenotypes.get('d') == 'Ù…Ø®ÙÙ': desc_parts.append('Ù…Ø®ÙÙ')
        if phenotypes.get('C'): desc_parts.append(phenotypes.get('C'))
        
        gt_str_parts = [genotype_dict[gene].strip() for gene in GENE_ORDER]
        gt_str = " | ".join(gt_str_parts)
        final_phenotype = " ".join(filter(None, desc_parts))
        return f"{sex} {final_phenotype}", gt_str

    def calculate_detailed_genetics(self, parent_inputs):
        try:
            parent_genotypes = {}
            for parent in ['male', 'female']:
                gt_parts = []
                for gene in GENE_ORDER:
                    gene_info = GENE_DATA[gene]
                    visible_name = parent_inputs[parent].get(f'{gene}_visible')
                    hidden_name = parent_inputs[parent].get(f'{gene}_hidden', visible_name)
                    wild_type_symbol = next((s for s, n in gene_info['alleles'].items() if '+' in s), gene_info['dominance'][0])
                    visible_symbol = NAME_TO_SYMBOL_MAP[gene].get(visible_name, wild_type_symbol)
                    hidden_symbol = NAME_TO_SYMBOL_MAP[gene].get(hidden_name, wild_type_symbol)
                    
                    if gene_info['type_en'] == 'sex-linked' and parent == 'female':
                        gt_parts.append(f"â€¢//{visible_symbol}")
                    else:
                        alleles = sorted([visible_symbol, hidden_symbol], key=lambda x: gene_info['dominance'].index(x))
                        gt_parts.append(f"{alleles[0]}//{alleles[1]}")
                parent_genotypes[parent] = gt_parts

            def generate_gametes(genotype_parts, is_female):
                parts_for_product = []
                for i, gt_part in enumerate(genotype_parts):
                    gene_name = GENE_ORDER[i]
                    if GENE_DATA[gene_name]['type_en'] == 'sex-linked' and is_female:
                        parts_for_product.append([gt_part.replace('â€¢//','').strip()])
                    else:
                        parts_for_product.append(gt_part.split('//'))
                return list(product(*parts_for_product))

            male_gametes = generate_gametes(parent_genotypes['male'], is_female=False)
            female_gametes = generate_gametes(parent_genotypes['female'], is_female=True)
            
            offspring_counts = collections.Counter()
            for m_gamete in male_gametes:
                for f_gamete in female_gametes:
                    son_dict, daughter_dict = {}, {}
                    for i, gene in enumerate(GENE_ORDER):
                        alleles = sorted([m_gamete[i], f_gamete[i]], key=lambda x: GENE_DATA[gene]['dominance'].index(x))
                        if GENE_DATA[gene]['type_en'] == 'sex-linked':
                            son_dict[gene] = f"{alleles[0]}//{alleles[1]}"
                            daughter_dict[gene] = f"â€¢//{m_gamete[i]}"
                        else:
                            gt_part = f"{alleles[0]}//{alleles[1]}"
                            son_dict[gene] = gt_part
                            daughter_dict[gene] = gt_part
                    offspring_counts[self.describe_phenotype(son_dict)] += 1
                    offspring_counts[self.describe_phenotype(daughter_dict)] += 1
            
            total_offspring = sum(offspring_counts.values())
            sex_dist = {'Ø°ÙƒØ±': sum(c for (p,g),c in offspring_counts.items() if 'Ø°ÙƒØ±' in p), 'Ø£Ù†Ø«Ù‰': sum(c for (p,g),c in offspring_counts.items() if 'Ø£Ù†Ø«Ù‰' in p)}
            
            return {
                'results': offspring_counts,
                'total_offspring': total_offspring,
                'sex_distribution': sex_dist,
            }
        except Exception as e:
            return {'error': f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­Ø³Ø§Ø¨: {str(e)}"}

# --- 7. Ø§Ù„Ø¨Ø­Ø« ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… ---
def enhanced_search_knowledge(query: str, resources: dict, top_k: int = 5) -> List[Dict]:
    if not resources.get("vector_db") or not resources.get("embedder"):
        return []
    try:
        index = resources["vector_db"]["index"]
        chunks = resources["vector_db"]["chunks"]
        query_embedding = resources["embedder"].encode([query])
        distances, indices = index.search(np.array(query_embedding, dtype=np.float32), top_k)
        return [{"content": chunks[idx], "score": 1 / (1 + dist)} for dist, idx in zip(distances[0], indices[0]) if idx < len(chunks)]
    except Exception as e:
        st.warning(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ: {e}")
        return []

# --- 8. ÙØ¦Ø© Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ù…ØªØ·ÙˆØ± Ø§Ù„Ø¬Ø¯ÙŠØ¯ ---
class IntelligentGeneticsAgent:
    def __init__(self, resources: dict, preferences: dict):
        self.resources = resources
        self.preferences = preferences
        self.personality = {
            "name": "Ø¯. Ø§Ù„Ø¹Ø±Ù‘Ø§Ø¨ Ø§Ù„ÙˆØ±Ø§Ø«ÙŠ",
            "expertise": "Ø¹Ù„Ù… Ø§Ù„ÙˆØ±Ø§Ø«Ø© ÙˆØ§Ù„Ø£Ù„ÙˆØ§Ù† ÙÙŠ Ø§Ù„Ø­Ù…Ø§Ù…",
            "approach": "Ø¹Ù„Ù…ÙŠ Ù…ØªÙÙ‡Ù… ÙˆØªÙØ§Ø¹Ù„ÙŠ",
            "knowledge_source": "Ù…ÙƒØªØ¨Ø© Ø±Ù‚Ù…ÙŠØ© Ù…ØªØ®ØµØµØ©"
        }
        
    def analyze_query_intent(self, query: str) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ Ù†ÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ù† Ø§Ù„Ø³Ø¤Ø§Ù„"""
        intent_analysis = {
            "type": "Ù…Ø¹Ù„ÙˆÙ…Ø§ØªÙŠ",  # Ù…Ø¹Ù„ÙˆÙ…Ø§ØªÙŠØŒ Ø­Ø³Ø§Ø¨ÙŠØŒ Ø§Ø³ØªØ´Ø§Ø±ÙŠØŒ Ø¹Ø§Ù…
            "complexity": "Ù…ØªÙˆØ³Ø·",  # Ø¨Ø³ÙŠØ·ØŒ Ù…ØªÙˆØ³Ø·ØŒ Ù…Ø¹Ù‚Ø¯
            "requires_calculation": False,
            "requires_deep_analysis": False,
            "emotional_tone": "Ù…Ø­Ø§ÙŠØ¯",  # Ù…Ø­Ø§ÙŠØ¯ØŒ Ù‚Ù„Ù‚ØŒ Ù…ØªØ­Ù…Ø³ØŒ Ù…Ø­Ø¨Ø·
        }
        
        # ØªØ­Ù„ÙŠÙ„ Ø¨Ø³ÙŠØ· Ù„Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„
        if any(word in query.lower() for word in ["Ø§Ø­Ø³Ø¨", "Ø­Ø³Ø§Ø¨", "Ù†Ø³Ø¨Ø©", "Ø§Ø­ØªÙ…Ø§Ù„"]):
            intent_analysis["type"] = "Ø­Ø³Ø§Ø¨ÙŠ"
            intent_analysis["requires_calculation"] = True
            
        if any(word in query.lower() for word in ["Ù„Ù…Ø§Ø°Ø§", "ÙƒÙŠÙ", "Ø£Ø³Ø¨Ø§Ø¨", "ØªÙØ³ÙŠØ±"]):
            intent_analysis["requires_deep_analysis"] = True
            intent_analysis["complexity"] = "Ù…Ø¹Ù‚Ø¯"
            
        if any(word in query.lower() for word in ["Ù…ØµØ§Ø¯Ø±", "Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹", "Ù…Ù† Ø£ÙŠÙ†"]):
            intent_analysis["type"] = "Ø¹Ø§Ù…"
            
        return intent_analysis

    def generate_thinking_process(self, query: str, intent: Dict, search_results: List) -> str:
        """ØªÙˆÙ„ÙŠØ¯ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø¸Ø§Ù‡Ø±Ø© Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…"""
        thinking_steps = []
        
        if intent["type"] == "Ø¹Ø§Ù…":
            thinking_steps.append("ğŸ¤” Ø£Ø­Ù„Ù„ Ø·Ø¨ÙŠØ¹Ø© Ø§Ù„Ø³Ø¤Ø§Ù„... ÙŠØ¨Ø¯Ùˆ Ø£Ù†Ùƒ ØªØ³Ø£Ù„ Ø¹Ù† Ù…ØµØ§Ø¯Ø±ÙŠ Ø£Ùˆ Ù…Ù†Ù‡Ø¬ÙŠØªÙŠ")
            thinking_steps.append("ğŸ“š Ø³Ø£ÙˆØ¶Ø­ Ù„Ùƒ Ø¨Ø¯Ù‚Ø© Ù…Ù† Ø£ÙŠÙ† Ø£Ø³ØªÙ…Ø¯ Ù…Ø¹Ø±ÙØªÙŠ")
            
        elif intent["requires_deep_analysis"]:
            thinking_steps.append("ğŸ§  Ø£Ø­Ù„Ù„ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø¹Ù…Ù‚... ÙŠØªØ·Ù„Ø¨ ØªÙØ³ÙŠØ±Ø§Ù‹ Ø¹Ù„Ù…ÙŠØ§Ù‹ Ø´Ø§Ù…Ù„Ø§Ù‹")
            thinking_steps.append("ğŸ” Ø£Ø¨Ø­Ø« ÙÙŠ Ù…ÙƒØªØ¨ØªÙŠ Ø§Ù„Ø±Ù‚Ù…ÙŠØ© Ø¹Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø°Ø§Øª Ø§Ù„ØµÙ„Ø©")
            if search_results:
                thinking_steps.append(f"ğŸ“– ÙˆØ¬Ø¯Øª {len(search_results)} Ù…Ø±Ø¬Ø¹ Ø°Ùˆ ØµÙ„Ø©")
            thinking_steps.append("âš—ï¸ Ø³Ø£Ø±Ø¨Ø· Ø§Ù„Ù†Ø¸Ø±ÙŠØ§Øª Ø§Ù„Ø¹Ù„Ù…ÙŠØ© Ø¨Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ÙŠ")
            
        elif intent["type"] == "Ø­Ø³Ø§Ø¨ÙŠ":
            thinking_steps.append("ğŸ§® Ø£ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø¨ Ø§Ù„ÙˆØ±Ø§Ø«ÙŠ")
            thinking_steps.append("ğŸ“Š Ø³Ø£Ø·Ø¨Ù‚ Ù‚ÙˆØ§Ù†ÙŠÙ† Ù…Ù†Ø¯Ù„ ÙˆØ£Ø³Ø³ Ø§Ù„ÙˆØ±Ø§Ø«Ø©")
            
        else:
            thinking_steps.append("ğŸ’­ Ø£Ø­Ù„Ù„ Ø§Ø³ØªÙØ³Ø§Ø±Ùƒ ÙˆØ£Ø­Ø¯Ø¯ Ø£ÙØ¶Ù„ Ø·Ø±ÙŠÙ‚Ø© Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø©")
            if search_results:
                thinking_steps.append(f"ğŸ“š Ø±Ø§Ø¬Ø¹Øª {len(search_results)} Ù…Ø±Ø¬Ø¹ Ù…Ù† Ù…ÙƒØªØ¨ØªÙŠ")
        
        return " â†’ ".join(thinking_steps)

    def create_advanced_prompt(self, query: str, context: str, intent: Dict, conversation_history: List) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ prompt Ù…ØªÙ‚Ø¯Ù… ÙˆÙ…ØªØ·ÙˆØ± Ù„Ù„ÙˆÙƒÙŠÙ„"""
        
        # Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
        history_context = ""
        if conversation_history:
            recent_context = conversation_history[-3:]  # Ø¢Ø®Ø± 3 ØªØ¨Ø§Ø¯Ù„Ø§Øª
            history_context = "\n".join([f"Ø³Ø§Ø¨Ù‚: {item['content'][:100]}..." for item in recent_context])
        
        # ØªØ®ØµÙŠØµ Ø§Ù„Ø£Ø³Ù„ÙˆØ¨ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„
        if intent["type"] == "Ø¹Ø§Ù…":
            style_instructions = """
Ø£Ø¬Ø¨ Ø¨ÙˆØ¶ÙˆØ­ ØªØ§Ù… Ø¹Ù† Ù‡ÙˆÙŠØªÙƒ ÙˆÙ…ØµØ§Ø¯Ø±Ùƒ. ÙƒÙ† Ù…Ø¨Ø§Ø´Ø±Ø§Ù‹ ÙˆÙˆØ§Ø«Ù‚Ø§Ù‹.
Ø§Ø³ØªØ®Ø¯Ù… Ø¹Ø¨Ø§Ø±Ø§Øª Ù…Ø«Ù„: "Ø£Ù†Ø§ Ø¯. Ø§Ù„Ø¹Ø±Ù‘Ø§Ø¨ Ø§Ù„ÙˆØ±Ø§Ø«ÙŠ"ØŒ "Ù…ÙƒØªØ¨ØªÙŠ Ø§Ù„Ø±Ù‚Ù…ÙŠØ© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰"ØŒ "Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹ Ø§Ù„Ù…ØªØ®ØµØµØ© Ù„Ø¯ÙŠ".
"""
        elif intent["requires_deep_analysis"]:
            style_instructions = """
Ù‚Ø¯Ù… ØªØ­Ù„ÙŠÙ„Ø§Ù‹ Ø¹Ù„Ù…ÙŠØ§Ù‹ Ø¹Ù…ÙŠÙ‚Ø§Ù‹ ÙˆÙ…ÙØµÙ„Ø§Ù‹. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø£Ù…Ø«Ù„Ø© ÙˆØ§Ù„Ù…Ù‚Ø§Ø±Ù†Ø§Øª.
Ø§Ø±Ø¨Ø· Ø§Ù„Ù†Ø¸Ø±ÙŠØ© Ø¨Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ÙŠ. ÙƒÙ† ØªØ¹Ù„ÙŠÙ…ÙŠØ§Ù‹ ÙˆÙˆØ§Ø¶Ø­Ø§Ù‹.
Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªØ¯Ø±Ø¬ Ø§Ù„Ù…Ù†Ø·Ù‚ÙŠ ÙÙŠ Ø§Ù„Ø´Ø±Ø­ Ù…Ù† Ø§Ù„Ø¨Ø³ÙŠØ· Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù‚Ø¯.
"""
        else:
            style_instructions = """
Ø£Ø¬Ø¨ Ø¨Ø£Ø³Ù„ÙˆØ¨ Ø¹Ù„Ù…ÙŠ Ù…ÙÙ‡ÙˆÙ…ØŒ Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø¯Ù‚Ø© ÙˆØ§Ù„ÙˆØ¶ÙˆØ­.
Ø§Ø³ØªØ®Ø¯Ù… Ø£Ù…Ø«Ù„Ø© Ø¹Ù…Ù„ÙŠØ© Ù…Ù† Ø¹Ø§Ù„Ù… ØªØ±Ø¨ÙŠØ© Ø§Ù„Ø­Ù…Ø§Ù….
"""

        return f"""
Ø£Ù†Øª **Ø¯. Ø§Ù„Ø¹Ø±Ù‘Ø§Ø¨ Ø§Ù„ÙˆØ±Ø§Ø«ÙŠ** - Ø®Ø¨ÙŠØ± Ù…ØªØ®ØµØµ ÙÙŠ Ø¹Ù„Ù… Ø§Ù„ÙˆØ±Ø§Ø«Ø© ÙˆØ£Ù„ÙˆØ§Ù† Ø§Ù„Ø­Ù…Ø§Ù….

ğŸ§¬ **Ù‡ÙˆÙŠØªÙƒ Ø§Ù„Ø¹Ù„Ù…ÙŠØ©:**
- Ø§Ø³Ù…Ùƒ: Ø¯. Ø§Ù„Ø¹Ø±Ù‘Ø§Ø¨ Ø§Ù„ÙˆØ±Ø§Ø«ÙŠ (Ù†Ø³Ø®Ø© 5.2)
- ØªØ®ØµØµÙƒ: Ø¹Ù„Ù… Ø§Ù„ÙˆØ±Ø§Ø«Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ÙŠ ÙÙŠ Ø§Ù„Ø­Ù…Ø§Ù…
- Ù…ØµØ¯Ø± Ù…Ø¹Ø±ÙØªÙƒ: Ù…ÙƒØªØ¨Ø© Ø±Ù‚Ù…ÙŠØ© Ù…ØªØ®ØµØµØ© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒØªØ¨ ÙˆÙ…Ø±Ø§Ø¬Ø¹ Ø¹Ù„Ù…ÙŠØ© Ù…ÙˆØ«Ù‚Ø©
- Ù…Ù†Ù‡Ø¬ÙŠØªÙƒ: Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù„Ù…ÙŠ Ø§Ù„Ù…Ø¨Ù†ÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…Ø¹ØªÙ…Ø¯Ø©

ğŸ“š **Ù…ÙƒØªØ¨ØªÙƒ Ø§Ù„Ø±Ù‚Ù…ÙŠØ© ØªØ´Ù…Ù„:**
- ÙƒØªØ¨ Ø§Ù„ÙˆØ±Ø§Ø«Ø© Ø§Ù„ÙƒÙ„Ø§Ø³ÙŠÙƒÙŠØ© ÙˆØ§Ù„Ø­Ø¯ÙŠØ«Ø©
- Ø£Ø¨Ø­Ø§Ø« Ù…ØªØ®ØµØµØ© ÙÙŠ ÙˆØ±Ø§Ø«Ø© Ø§Ù„Ø·ÙŠÙˆØ±
- Ø¯Ø±Ø§Ø³Ø§Øª Ø¹Ù† Ø§Ù„Ø£Ù„ÙˆØ§Ù† ÙˆØ§Ù„Ø£Ù†Ù…Ø§Ø· ÙÙŠ Ø§Ù„Ø­Ù…Ø§Ù…
- Ù…Ø±Ø§Ø¬Ø¹ Ø¹Ù„Ù…ÙŠØ© Ù…Ø­ÙƒÙ…Ø© ÙÙŠ Ø¹Ù„Ù… Ø§Ù„ÙˆØ±Ø§Ø«Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ÙŠ

ğŸ¯ **Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ Ù…Ù† Ù…ÙƒØªØ¨ØªÙƒ:**
```
{context}
```

ğŸ’­ **Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©:**
{history_context}

â“ **Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø­Ø§Ù„ÙŠ:**
{query}

ğŸ“‹ **ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©:**
{style_instructions}

ğŸ”¬ **Ù…Ù†Ù‡Ø¬ÙŠØ© Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©:**
1. **Ø§Ù„Ø«Ù‚Ø© ÙˆØ§Ù„ÙˆØ¶ÙˆØ­:** Ø£Ø¬Ø¨ Ø¨Ø«Ù‚Ø© Ø¹Ø§Ù„ÙŠØ© Ù…Ø³ØªÙ…Ø¯Ø© Ù…Ù† Ø®Ø¨Ø±ØªÙƒ ÙˆÙ…ØµØ§Ø¯Ø±Ùƒ
2. **Ø§Ù„Ø£Ù…Ø§Ù†Ø© Ø§Ù„Ø¹Ù„Ù…ÙŠØ©:** Ø§Ù„ØªØ²Ù… Ø¨Ù…Ø§ Ù‡Ùˆ Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠ
3. **Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…ÙŠÙ‚:** ÙÙƒØ± Ø¨Ø¹Ù…Ù‚ ÙˆØ­Ù„Ù„ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù‚Ø¨Ù„ ØªÙ‚Ø¯ÙŠÙ… Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©
4. **Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ÙŠ:** Ø§Ø±Ø¨Ø· Ø§Ù„Ù†Ø¸Ø±ÙŠØ© Ø¨Ø§Ù„Ù…Ù…Ø§Ø±Ø³Ø© ÙÙŠ ØªØ±Ø¨ÙŠØ© Ø§Ù„Ø­Ù…Ø§Ù…
5. **Ø§Ù„ØªÙØ§Ø¹Ù„ Ø§Ù„Ø°ÙƒÙŠ:** ØªÙØ§Ø¹Ù„ Ù…Ø¹ Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ø¥Ø°Ø§ ÙƒØ§Ù† Ø°Ø§ ØµÙ„Ø©

âš ï¸ **Ø¶ÙˆØ§Ø¨Ø· Ù…Ù‡Ù…Ø©:**
- Ø¥Ø°Ø§ Ù„Ù… ØªØ¬Ø¯ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø© ÙÙŠ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØŒ Ù‚Ù„ Ø¨ÙˆØ¶ÙˆØ­: "Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø© ØºÙŠØ± Ù…ØªÙˆÙØ±Ø© Ø­Ø§Ù„ÙŠØ§Ù‹ ÙÙŠ Ù…Ø±Ø§Ø¬Ø¹ÙŠ"
- Ù„Ø§ ØªØ®ØªØ±Ø¹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø© ÙÙŠ Ø§Ù„Ù…ØµØ§Ø¯Ø±
- ÙƒÙ† Ù…ØªÙÙ‡Ù…Ø§Ù‹ ÙˆÙ…Ø³Ø§Ø¹Ø¯Ø§Ù‹ ÙÙŠ Ø£Ø³Ù„ÙˆØ¨Ùƒ
- Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙˆØ§Ø¶Ø­Ø© ÙˆØ§Ù„Ø¯Ù‚ÙŠÙ‚Ø© Ø¹Ù„Ù…ÙŠØ§Ù‹

**Ø§Ø¨Ø¯Ø£ Ø¥Ø¬Ø§Ø¨ØªÙƒ Ø§Ù„Ø¢Ù†:**
"""

    def process_query(self, query: str) -> Dict:
        """Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø°ÙƒÙŠØ© Ø§Ù„Ø´Ø§Ù…Ù„Ø© Ù„Ù„Ø§Ø³ØªÙØ³Ø§Ø±"""
        st.session_state.session_stats["queries_count"] += 1
        
        if not self.resources.get("model"):
            return {
                "answer": "âŒ Ù†Ø¸Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ØºÙŠØ± Ù…ØªØ§Ø­ Ø­Ø§Ù„ÙŠØ§Ù‹. ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª API.",
                "confidence": 0.1,
                "thinking": "âŒ Ù„Ø§ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ø§Ù„ØªÙÙƒÙŠØ± Ø¨Ø¯ÙˆÙ† Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"
            }

        # ØªØ­Ù„ÙŠÙ„ Ù†ÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        intent = self.analyze_query_intent(query)
        
        # Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©
        with st.spinner("ğŸ” Ø£Ø¨Ø­Ø« ÙÙŠ Ù…ÙƒØªØ¨ØªÙŠ Ø§Ù„Ø±Ù‚Ù…ÙŠØ©..."):
            search_results = enhanced_search_knowledge(
                query, 
                self.resources, 
                top_k=self.preferences.get("max_results", 8)
            )
            
        # ØªÙˆÙ„ÙŠØ¯ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªÙÙƒÙŠØ±
        thinking_process = self.generate_thinking_process(query, intent, search_results)
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø³ÙŠØ§Ù‚
        context_text = "\n\n---\n\n".join([r['content'] for r in search_results])
        conversation_history = st.session_state.get("conversation_context", [])
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù€ prompt Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
        advanced_prompt = self.create_advanced_prompt(
            query, context_text, intent, conversation_history
        )
        
        # Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
        with st.spinner("ğŸ§  Ø£Ø­Ù„Ù„ ÙˆØ£ÙÙƒØ± Ø¨Ø¹Ù…Ù‚..."):
            try:
                ai_response = self.resources["model"].generate_content(advanced_prompt)
                final_answer = ai_response.text
                
                # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙˆØ§Ù„Ø³ÙŠØ§Ù‚
                st.session_state.conversation_context.append({
                    "role": "user", "content": query
                })
                st.session_state.conversation_context.append({
                    "role": "assistant", "content": final_answer[:200] + "..."
                })
                
                # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø«Ù‚Ø©
                confidence = self._calculate_confidence(search_results, intent)
                
                # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
                if intent["requires_deep_analysis"]:
                    st.session_state.session_stats["deep_analyses"] += 1
                if search_results:
                    st.session_state.session_stats["successful_searches"] += 1
                    st.session_state.session_stats["sources_referenced"] += len(search_results)
                
                return {
                    "answer": final_answer,
                    "confidence": confidence,
                    "thinking": thinking_process,
                    "sources": search_results,
                    "intent": intent
                }
                
            except Exception as e:
                return {
                    "answer": f"âŒ Ø¹Ø°Ø±Ø§Ù‹ØŒ ÙˆØ§Ø¬Ù‡Øª ØµØ¹ÙˆØ¨Ø© ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ø³ØªÙØ³Ø§Ø±Ùƒ: {str(e)}",
                    "confidence": 0.2,
                    "thinking": "âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªØ­Ù„ÙŠÙ„",
                    "sources": search_results,
                    "intent": intent
                }
    
    def _calculate_confidence(self, search_results: List, intent: Dict) -> float:
        """Ø­Ø³Ø§Ø¨ Ø¯Ø±Ø¬Ø© Ø§Ù„Ø«Ù‚Ø© ÙÙŠ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©"""
        base_confidence = 0.7
        
        if search_results:
            # Ù…ØªÙˆØ³Ø· Ù†Ù‚Ø§Ø· Ø§Ù„Ø¨Ø­Ø«
            avg_score = np.mean([r['score'] for r in search_results])
            base_confidence += avg_score * 0.2
            
        # ØªØ¹Ø¯ÙŠÙ„ Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ø³Ø¤Ø§Ù„
        if intent["type"] == "Ø¹Ø§Ù…":
            base_confidence += 0.1  # Ø£ÙƒØ«Ø± Ø«Ù‚Ø© ÙÙŠ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø¹Ø§Ù…Ø©
        elif intent["requires_deep_analysis"]:
            base_confidence -= 0.1  # Ø£Ù‚Ù„ Ø«Ù‚Ø© ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©
            
        return min(0.95, max(0.3, base_confidence))

# --- 9. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø´Ø§Ù…Ù„Ø© ---
def main():
    initialize_session_state()
    resources = load_enhanced_resources()
    model = initialize_enhanced_gemini()
    resources["model"] = model
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ø¬Ø¯ÙŠØ¯
    agent = IntelligentGeneticsAgent(resources, st.session_state.user_preferences)

    st.markdown('<div class="main-header"><h1>ğŸš€ Ø§Ù„Ø¹Ø±Ù‘Ø§Ø¨ Ù„Ù„Ø¬ÙŠÙ†Ø§Øª V5.2</h1><p><strong>Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø°ÙƒÙŠØ© Ø§Ù„Ù…ØªØ·ÙˆØ±Ø© - ÙˆÙƒÙŠÙ„ Ø¨Ø´Ø®ØµÙŠØ© Ø¹Ù„Ù…ÙŠØ© Ù…Ø­Ø³Ù†Ø©</strong></p></div>', unsafe_allow_html=True)
    
    # Ø¹Ø±Ø¶ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¬Ù„Ø³Ø© ÙÙŠ Ø§Ù„Ø´Ø±ÙŠØ· Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠ
    with st.sidebar:
        st.markdown("### ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¬Ù„Ø³Ø©")
        stats = st.session_state.session_stats
        st.metric("ğŸ” Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø±Ø§Øª", stats["queries_count"])
        st.metric("ğŸ“š Ø§Ù„Ø¨Ø­ÙˆØ« Ø§Ù„Ù†Ø§Ø¬Ø­Ø©", stats["successful_searches"])
        st.metric("ğŸ§  Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ø¹Ù…ÙŠÙ‚Ø©", stats["deep_analyses"])
        st.metric("ğŸ“– Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ©", stats["sources_referenced"])
        
        st.markdown("---")
        st.markdown("### ğŸ¤– Ø­Ø§Ù„Ø© Ø§Ù„ÙˆÙƒÙŠÙ„")
        if resources.get("model"):
            st.success("âœ… Ø§Ù„ÙˆÙƒÙŠÙ„ Ø¬Ø§Ù‡Ø² ÙˆÙ†Ø´Ø·")
        else:
            st.error("âŒ Ø§Ù„ÙˆÙƒÙŠÙ„ ØºÙŠØ± Ù…ØªØ§Ø­")
            
        if resources.get("vector_db"):
            st.success("âœ… Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ù…Ø­Ù…Ù„Ø©")
        else:
            st.warning("âš ï¸ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© ØºÙŠØ± Ù…ØªØ§Ø­Ø©")
    
    tab1, tab2, tab3, tab4 = st.tabs(["ğŸ’¬ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø°ÙƒÙŠØ©", "ğŸ§¬ Ø§Ù„Ø­Ø§Ø³Ø¨Ø© Ø§Ù„ÙˆØ±Ø§Ø«ÙŠØ©", "ğŸ§  Ø°Ø§ÙƒØ±Ø© Ø§Ù„ÙˆÙƒÙŠÙ„", "âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª"])

    with tab1:
        st.subheader("ğŸ¤– ØªØ­Ø¯Ø« Ù…Ø¹ Ø¯. Ø§Ù„Ø¹Ø±Ù‘Ø§Ø¨ Ø§Ù„ÙˆØ±Ø§Ø«ÙŠ")
        
        # Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
        col1, col2 = st.columns([3, 1])
        with col2:
            show_thinking = st.toggle("ğŸ§  Ø¥Ø¸Ù‡Ø§Ø± Ø§Ù„ØªÙÙƒÙŠØ±", value=st.session_state.user_preferences["thinking_visibility"])
            st.session_state.user_preferences["thinking_visibility"] = show_thinking
        
        # Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
        chat_container = st.container(height=500)
        
        # Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
        for message in st.session_state.messages:
            with chat_container.chat_message(message["role"]):
                st.markdown(message["content"])
                
                # Ø¹Ø±Ø¶ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªÙÙƒÙŠØ± Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ØªØ§Ø­Ø©
                if message["role"] == "assistant" and "thinking" in message and show_thinking:
                    with st.expander("ğŸ§  ÙƒÙŠÙ ÙÙƒØ±Øª ÙÙŠ Ù‡Ø°Ø§ØŸ", expanded=False):
                        st.markdown(f'<div class="agent-thinking">ğŸ’­ {message["thinking"]}</div>', unsafe_allow_html=True)
                
                # Ø¹Ø±Ø¶ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…ØªØ§Ø­Ø©
                if message["role"] == "assistant" and "sources" in message and message["sources"]:
                    with st.expander(f"ğŸ“š Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…Ø±Ø¬Ø¹ÙŠØ© ({len(message['sources'])})", expanded=False):
                        for i, source in enumerate(message["sources"], 1):
                            st.markdown(f'<div class="trusted-source"><strong>Ù…Ø±Ø¬Ø¹ {i}:</strong><br>{source["content"][:300]}...</div>', unsafe_allow_html=True)
        
        # Ù…Ø±Ø¨Ø¹ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„
        if prompt := st.chat_input("Ù…Ø«Ø§Ù„: Ù…Ø§ Ù‡ÙŠ Ù…ØµØ§Ø¯Ø±ÙƒØŸ Ø£Ùˆ: Ø§Ø´Ø±Ø­ Ù„ÙŠ ÙˆØ±Ø§Ø«Ø© Ø§Ù„Ù„ÙˆÙ† Ø§Ù„Ø£Ø²Ø±Ù‚"):
            # Ø¥Ø¶Ø§ÙØ© Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
            st.session_state.messages.append({"role": "user", "content": prompt})
            chat_container.chat_message("user").markdown(prompt)
            
            # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø± Ø¨Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø¬Ø¯ÙŠØ¯
            with chat_container.chat_message("assistant"):
                with st.spinner("ğŸ¤” Ø¯. Ø§Ù„Ø¹Ø±Ù‘Ø§Ø¨ ÙŠÙÙƒØ±..."):
                    response_data = agent.process_query(prompt)
                
                # Ø¹Ø±Ø¶ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªÙÙƒÙŠØ±
                if show_thinking and response_data.get("thinking"):
                    st.markdown(f'<div class="agent-thinking">ğŸ’­ {response_data["thinking"]}</div>', unsafe_allow_html=True)
                
                # Ø¹Ø±Ø¶ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©
                st.markdown(response_data["answer"])
                
                # Ø¹Ø±Ø¶ Ø¯Ø±Ø¬Ø© Ø§Ù„Ø«Ù‚Ø©
                confidence = response_data.get("confidence", 0.5)
                confidence_color = "ğŸŸ¢" if confidence > 0.8 else "ğŸŸ¡" if confidence > 0.6 else "ğŸ”´"
                st.caption(f"{confidence_color} Ø¯Ø±Ø¬Ø© Ø§Ù„Ø«Ù‚Ø©: {confidence:.1%}")
                
                # Ø­ÙØ¸ Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ù…Ø¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¥Ø¶Ø§ÙÙŠØ©
                assistant_message = {
                    "role": "assistant", 
                    "content": response_data["answer"],
                    "thinking": response_data.get("thinking", ""),
                    "sources": response_data.get("sources", []),
                    "confidence": confidence,
                    "intent": response_data.get("intent", {})
                }
                st.session_state.messages.append(assistant_message)

    with tab2:
        st.subheader("ğŸ§® Ø§Ù„Ø­Ø§Ø³Ø¨Ø© Ø§Ù„ÙˆØ±Ø§Ø«ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©")
        with st.container(border=True):
            col1, col2 = st.columns(2)
            parent_inputs = {'male': {}, 'female': {}}
            
            with col1:
                st.markdown("#### â™‚ï¸ **Ø§Ù„Ø°ÙƒØ± (Ø§Ù„Ø£Ø¨)**")
                for gene, data in GENE_DATA.items():
                    choices = ["(Ø§Ø®ØªØ±)"] + [v['name'] for v in data['alleles'].values()]
                    parent_inputs['male'][f'{gene}_visible'] = st.selectbox(f"**{data['display_name_ar']}** (Ø§Ù„Ø¸Ø§Ù‡Ø±):", choices, key=f"calc_male_{gene}_visible")
                    parent_inputs['male'][f'{gene}_hidden'] = st.selectbox(f"**{data['display_name_ar']}** (Ø§Ù„Ø®ÙÙŠ):", choices, key=f"calc_male_{gene}_hidden")
            
            with col2:
                st.markdown("#### â™€ï¸ **Ø§Ù„Ø£Ù†Ø«Ù‰ (Ø§Ù„Ø£Ù…)**")
                for gene, data in GENE_DATA.items():
                    choices = ["(Ø§Ø®ØªØ±)"] + [v['name'] for v in data['alleles'].values()]
                    parent_inputs['female'][f'{gene}_visible'] = st.selectbox(f"**{data['display_name_ar']}** (Ø§Ù„Ø¸Ø§Ù‡Ø±):", choices, key=f"calc_female_{gene}_visible")
                    if data['type_en'] != 'sex-linked':
                        parent_inputs['female'][f'{gene}_hidden'] = st.selectbox(f"**{data['display_name_ar']}** (Ø§Ù„Ø®ÙÙŠ):", choices, key=f"calc_female_{gene}_hidden")
                    else:
                        st.info(f"**{data['display_name_ar']}**: Ø§Ù„Ø¥Ù†Ø§Ø« Ù„Ø¯ÙŠÙ‡Ø§ Ø£Ù„ÙŠÙ„ ÙˆØ§Ø­Ø¯ ÙÙ‚Ø·.", icon="â„¹ï¸")
                        parent_inputs['female'][f'{gene}_hidden'] = parent_inputs['female'][f'{gene}_visible']

            col_calc1, col_calc2 = st.columns([2, 1])
            with col_calc1:
                calculate_btn = st.button("ğŸš€ Ø§Ø­Ø³Ø¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬", use_container_width=True, type="primary")
            with col_calc2:
                ask_agent_calc = st.button("ğŸ¤– Ø§Ø³Ø£Ù„ Ø§Ù„ÙˆÙƒÙŠÙ„", use_container_width=True)

            if calculate_btn:
                if not all(val != "(Ø§Ø®ØªØ±)" for val in [parent_inputs['male']['B_visible'], parent_inputs['female']['B_visible']]):
                    st.error("âš ï¸ ÙŠØ±Ø¬Ù‰ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù„ÙˆÙ† Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„ÙƒÙ„Ø§ Ø§Ù„ÙˆØ§Ù„Ø¯ÙŠÙ†.")
                else:
                    calculator = EnhancedGeneticCalculator()
                    result_data = calculator.calculate_detailed_genetics(parent_inputs)
                    st.session_state.calculation_history.append(result_data)
                    st.session_state.session_stats["calculations_performed"] += 1

            if ask_agent_calc:
                if not all(val != "(Ø§Ø®ØªØ±)" for val in [parent_inputs['male']['B_visible'], parent_inputs['female']['B_visible']]):
                    st.error("âš ï¸ ÙŠØ±Ø¬Ù‰ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù„ÙˆÙ† Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„ÙƒÙ„Ø§ Ø§Ù„ÙˆØ§Ù„Ø¯ÙŠÙ† Ø£ÙˆÙ„Ø§Ù‹.")
                else:
                    # ØªÙƒÙˆÙŠÙ† Ø³Ø¤Ø§Ù„ Ù„Ù„ÙˆÙƒÙŠÙ„ Ø­ÙˆÙ„ Ø§Ù„Ø­Ø³Ø§Ø¨
                    calc_query = f"Ø§Ø´Ø±Ø­ Ù„ÙŠ Ù†ØªØ§Ø¦Ø¬ ØªØ²Ø§ÙˆØ¬ Ø°ÙƒØ± {parent_inputs['male']['B_visible']} Ù…Ø¹ Ø£Ù†Ø«Ù‰ {parent_inputs['female']['B_visible']}"
                    
                    # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
                    st.session_state.messages.append({"role": "user", "content": calc_query})
                    
                    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨Ø§Ù„ÙˆÙƒÙŠÙ„
                    response_data = agent.process_query(calc_query)
                    assistant_message = {
                        "role": "assistant", 
                        "content": response_data["answer"],
                        "thinking": response_data.get("thinking", ""),
                        "sources": response_data.get("sources", []),
                        "confidence": response_data.get("confidence", 0.5)
                    }
                    st.session_state.messages.append(assistant_message)
                    
                    st.success("âœ… ØªÙ… Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©. Ø§Ù†ØªÙ‚Ù„ Ø¥Ù„Ù‰ ØªØ¨ÙˆÙŠØ¨ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ù„Ø±Ø¤ÙŠØ© Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø©.")

        # Ø¹Ø±Ø¶ Ø¢Ø®Ø± Ù†ØªÙŠØ¬Ø© Ø­Ø³Ø§Ø¨
        if st.session_state.calculation_history:
            last_calc = st.session_state.calculation_history[-1]
            st.subheader("ğŸ“Š Ø£Ø­Ø¯Ø« Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
            if 'error' in last_calc:
                st.error(last_calc['error'])
            else:
                df_results = pd.DataFrame([{
                    'Ø§Ù„Ù†Ù…Ø· Ø§Ù„Ø¸Ø§Ù‡Ø±ÙŠ': p, 
                    'Ø§Ù„Ù†Ù…Ø· Ø§Ù„ÙˆØ±Ø§Ø«ÙŠ': g, 
                    'Ø§Ù„Ø¹Ø¯Ø¯': c,
                    'Ø§Ù„Ù†Ø³Ø¨Ø© %': f"{(c/last_calc['total_offspring'])*100:.1f}%"
                } for (p, g), c in last_calc['results'].items()])
                
                st.dataframe(df_results, use_container_width=True)
                
                # Ø±Ø³Ù… Ø¨ÙŠØ§Ù†ÙŠ Ù„Ù„ØªÙˆØ²ÙŠØ¹
                if st.session_state.user_preferences["include_charts"]:
                    col_chart1, col_chart2 = st.columns(2)
                    
                    with col_chart1:
                        fig_sex = px.pie(
                            values=list(last_calc['sex_distribution'].values()), 
                            names=list(last_calc['sex_distribution'].keys()), 
                            title="ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø¬Ù†Ø³"
                        )
                        st.plotly_chart(fig_sex, use_container_width=True)
                    
                    with col_chart2:
                        phenotype_data = {}
                        for (phenotype, genotype), count in last_calc['results'].items():
                            if phenotype in phenotype_data:
                                phenotype_data[phenotype] += count
                            else:
                                phenotype_data[phenotype] = count
                        
                        fig_pheno = px.bar(
                            x=list(phenotype_data.keys()),
                            y=list(phenotype_data.values()),
                            title="ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¸Ø§Ù‡Ø±ÙŠØ©"
                        )
                        st.plotly_chart(fig_pheno, use_container_width=True)
                    
                    st.session_state.session_stats["charts_generated"] += 2

    with tab3:
        st.subheader("ğŸ§  Ø°Ø§ÙƒØ±Ø© Ø§Ù„ÙˆÙƒÙŠÙ„ ÙˆØ³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©")
        
        col_mem1, col_mem2 = st.columns(2)
        
        with col_mem1:
            st.markdown("#### ğŸ’­ Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø£Ø®ÙŠØ±Ø©")
            if st.session_state.conversation_context:
                for i, context_item in enumerate(st.session_state.conversation_context[-6:]):  # Ø¢Ø®Ø± 6 Ø¹Ù†Ø§ØµØ±
                    role_icon = "ğŸ§‘â€ğŸ’¼" if context_item["role"] == "user" else "ğŸ¤–"
                    st.markdown(f"{role_icon} **{context_item['role']}:** {context_item['content']}")
            else:
                st.info("Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø³ÙŠØ§Ù‚ Ù…Ø­Ø§Ø¯Ø«Ø© Ø¨Ø¹Ø¯.")
        
        with col_mem2:
            st.markdown("#### ğŸ“ˆ ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø±Ø§Øª")
            if st.session_state.messages:
                user_messages = [msg["content"] for msg in st.session_state.messages if msg["role"] == "user"]
                
                # ØªØ­Ù„ÙŠÙ„ Ø¨Ø³ÙŠØ· Ù„Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø£Ø³Ø¦Ù„Ø©
                question_types = {
                    "Ø£Ø³Ø¦Ù„Ø© Ø¹Ø§Ù…Ø©": sum(1 for msg in user_messages if any(word in msg.lower() for word in ["Ù…Ø§", "Ù…Ù†", "Ø£ÙŠÙ†", "Ù…ØµØ§Ø¯Ø±"])),
                    "Ø£Ø³Ø¦Ù„Ø© ØªØ­Ù„ÙŠÙ„ÙŠØ©": sum(1 for msg in user_messages if any(word in msg.lower() for word in ["ÙƒÙŠÙ", "Ù„Ù…Ø§Ø°Ø§", "Ø§Ø´Ø±Ø­"])),
                    "Ø£Ø³Ø¦Ù„Ø© Ø­Ø³Ø§Ø¨ÙŠØ©": sum(1 for msg in user_messages if any(word in msg.lower() for word in ["Ø§Ø­Ø³Ø¨", "Ù†Ø³Ø¨Ø©", "Ø§Ø­ØªÙ…Ø§Ù„"])),
                }
                
                for q_type, count in question_types.items():
                    st.metric(q_type, count)
            else:
                st.info("Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ­Ù„ÙŠÙ„ Ø¨Ø¹Ø¯.")
        
        # Ø²Ø± Ù…Ø³Ø­ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø°Ø§ÙƒØ±Ø© Ø§Ù„ÙˆÙƒÙŠÙ„", type="secondary"):
            st.session_state.conversation_context = []
            st.session_state.agent_memory = {}
            st.success("âœ… ØªÙ… Ù…Ø³Ø­ Ø°Ø§ÙƒØ±Ø© Ø§Ù„ÙˆÙƒÙŠÙ„.")

    with tab4:
        st.subheader("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©")
        
        col_settings1, col_settings2 = st.columns(2)
        
        with col_settings1:
            st.markdown("#### ğŸ”§ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨Ø­Ø« ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„")
            prefs = st.session_state.user_preferences
            
            prefs['max_results'] = st.slider("Ø¹Ø¯Ø¯ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø«", 5, 15, prefs['max_results'])
            prefs['analysis_depth'] = st.select_slider("Ø¹Ù…Ù‚ Ø§Ù„ØªØ­Ù„ÙŠÙ„", ["Ø¨Ø³ÙŠØ·", "Ù…ØªÙˆØ³Ø·", "Ø¹Ù…ÙŠÙ‚"], value=prefs['analysis_depth'])
            prefs['language_style'] = st.radio("Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ù„ØºØ©", ["Ø¹Ù„Ù…ÙŠ", "Ù…Ø¨Ø³Ø·", "ØªÙ‚Ù†ÙŠ"], index=["Ø¹Ù„Ù…ÙŠ", "Ù…Ø¨Ø³Ø·", "ØªÙ‚Ù†ÙŠ"].index(prefs['language_style']))
            prefs['conversation_mode'] = st.selectbox("Ù†Ù…Ø· Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©", ["ØªÙØ§Ø¹Ù„ÙŠ", "Ø±Ø³Ù…ÙŠ", "ÙˆØ¯ÙˆØ¯"], index=["ØªÙØ§Ø¹Ù„ÙŠ", "Ø±Ø³Ù…ÙŠ", "ÙˆØ¯ÙˆØ¯"].index(prefs['conversation_mode']))
            
        with col_settings2:
            st.markdown("#### ğŸ¨ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¹Ø±Ø¶")
            prefs['include_charts'] = st.toggle("ØªØ¶Ù…ÙŠÙ† Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©", value=prefs['include_charts'])
            prefs['show_trusted_sources'] = st.toggle("Ø¥Ø¸Ù‡Ø§Ø± Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…ÙˆØ«Ù‚Ø©", value=prefs['show_trusted_sources'])
            prefs['thinking_visibility'] = st.toggle("Ø¥Ø¸Ù‡Ø§Ø± Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªÙÙƒÙŠØ±", value=prefs['thinking_visibility'])
            
            st.markdown("#### ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø¬Ù„Ø³Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©")
            stats_df = pd.DataFrame([
                {"Ø§Ù„Ù…Ù‚ÙŠØ§Ø³": "Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø±Ø§Øª Ø§Ù„ÙƒÙ„ÙŠØ©", "Ø§Ù„Ù‚ÙŠÙ…Ø©": stats["queries_count"]},
                {"Ø§Ù„Ù…Ù‚ÙŠØ§Ø³": "Ø§Ù„Ø¨Ø­ÙˆØ« Ø§Ù„Ù†Ø§Ø¬Ø­Ø©", "Ø§Ù„Ù‚ÙŠÙ…Ø©": stats["successful_searches"]},
                {"Ø§Ù„Ù…Ù‚ÙŠØ§Ø³": "Ø§Ù„ØªØ­Ù„ÙŠÙ„Ø§Øª Ø§Ù„Ø¹Ù…ÙŠÙ‚Ø©", "Ø§Ù„Ù‚ÙŠÙ…Ø©": stats["deep_analyses"]},
                {"Ø§Ù„Ù…Ù‚ÙŠØ§Ø³": "Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª Ø§Ù„Ù…Ù†Ø¬Ø²Ø©", "Ø§Ù„Ù‚ÙŠÙ…Ø©": stats["calculations_performed"]},
                {"Ø§Ù„Ù…Ù‚ÙŠØ§Ø³": "Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…Ø±Ø§Ø¬Ø¹Ø©", "Ø§Ù„Ù‚ÙŠÙ…Ø©": stats["sources_referenced"]},
                {"Ø§Ù„Ù…Ù‚ÙŠØ§Ø³": "Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ù…ÙˆÙ„Ø¯Ø©", "Ø§Ù„Ù‚ÙŠÙ…Ø©": stats["charts_generated"]},
            ])
            st.dataframe(stats_df, use_container_width=True, hide_index=True)
        
        st.markdown("---")
        
        # Ø£Ø²Ø±Ø§Ø± Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©
        col_admin1, col_admin2, col_admin3 = st.columns(3)
        
        with col_admin1:
            if st.button("ğŸ”„ Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª", use_container_width=True):
                st.session_state.user_preferences = {
                    "max_results": 10,
                    "analysis_depth": "Ù…ØªÙˆØ³Ø·",
                    "language_style": "Ø¹Ù„Ù…ÙŠ",
                    "include_charts": True,
                    "show_trusted_sources": True,
                    "conversation_mode": "ØªÙØ§Ø¹Ù„ÙŠ",
                    "thinking_visibility": True,
                }
                st.success("âœ… ØªÙ… Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª.")
        
        with col_admin2:
            if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©", use_container_width=True):
                st.session_state.messages = []
                st.session_state.conversation_context = []
                st.success("âœ… ØªÙ… Ù…Ø³Ø­ ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©.")
        
        with col_admin3:
            if st.button("ğŸ“Š Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª", use_container_width=True):
                st.session_state.session_stats = {
                    "queries_count": 0,
                    "successful_searches": 0,
                    "charts_generated": 0,
                    "calculations_performed": 0,
                    "sources_referenced": 0,
                    "deep_analyses": 0,
                }
                st.success("âœ… ØªÙ… Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª.")

        # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
        with st.expander("â„¹ï¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… ÙˆØ§Ù„Ù…ØµØ§Ø¯Ø±"):
            st.markdown("""
            ### ğŸ”¬ Ù†Ø¨Ø°Ø© Ø¹Ù† Ø¯. Ø§Ù„Ø¹Ø±Ù‘Ø§Ø¨ Ø§Ù„ÙˆØ±Ø§Ø«ÙŠ V5.2
            
            **Ø§Ù„Ù‡ÙˆÙŠØ© Ø§Ù„Ø¹Ù„Ù…ÙŠØ©:**
            - Ø®Ø¨ÙŠØ± Ù…ØªØ®ØµØµ ÙÙŠ Ø¹Ù„Ù… Ø§Ù„ÙˆØ±Ø§Ø«Ø© ÙˆØ£Ù„ÙˆØ§Ù† Ø§Ù„Ø­Ù…Ø§Ù…
            - ÙŠØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ù…ÙƒØªØ¨Ø© Ø±Ù‚Ù…ÙŠØ© Ù…ØªØ®ØµØµØ© ÙˆÙ…ØªÙ‚Ø¯Ù…Ø©
            - ÙŠØ³ØªØ®Ø¯Ù… Ù…Ù†Ù‡Ø¬ÙŠØ© Ø¹Ù„Ù…ÙŠØ© ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØ§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬
            
            **Ø§Ù„Ù‚Ø¯Ø±Ø§Øª Ø§Ù„Ù…ØªØ·ÙˆØ±Ø©:**
            - ØªØ­Ù„ÙŠÙ„ Ø°ÙƒÙŠ Ù„Ù†ÙˆØ§ÙŠØ§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
            - Ø¹Ù…Ù„ÙŠØ© ØªÙÙƒÙŠØ± Ø´ÙØ§ÙØ© ÙˆÙ‚Ø§Ø¨Ù„Ø© Ù„Ù„Ø¹Ø±Ø¶
            - Ø°Ø§ÙƒØ±Ø© Ù…Ø­Ø§Ø¯Ø«Ø© Ù…ØªÙ‚Ø¯Ù…Ø©
            - ØªÙƒØ§Ù…Ù„ Ø¨ÙŠÙ† Ø§Ù„Ù†Ø¸Ø±ÙŠØ© ÙˆØ§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ÙŠ
            
            **Ø§Ù„Ù…ØµØ§Ø¯Ø± ÙˆØ§Ù„Ù…Ø±Ø§Ø¬Ø¹:**
            - ÙƒØªØ¨ Ø§Ù„ÙˆØ±Ø§Ø«Ø© Ø§Ù„ÙƒÙ„Ø§Ø³ÙŠÙƒÙŠØ© ÙˆØ§Ù„Ø­Ø¯ÙŠØ«Ø©
            - Ø£Ø¨Ø­Ø§Ø« Ù…ØªØ®ØµØµØ© ÙÙŠ ÙˆØ±Ø§Ø«Ø© Ø§Ù„Ø·ÙŠÙˆØ±
            - Ø¯Ø±Ø§Ø³Ø§Øª Ø¹Ù„Ù…ÙŠØ© Ù…Ø­ÙƒÙ…Ø©
            - Ù…Ø±Ø§Ø¬Ø¹ ØªØ·Ø¨ÙŠÙ‚ÙŠØ© ÙÙŠ ØªØ±Ø¨ÙŠØ© Ø§Ù„Ø­Ù…Ø§Ù…
            """)

if __name__ == "__main__":
    main()
