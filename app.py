# ===================================================================
# ğŸš€ Ø§Ù„Ø¹Ø±Ù‘Ø§Ø¨ Ù„Ù„Ø¬ÙŠÙ†Ø§Øª V5.0 - Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø´Ø§Ù…Ù„Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
# Ø¯Ù…Ø¬ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª: ÙˆØ§Ø¬Ù‡Ø© Ù…ØªÙ‚Ø¯Ù…Ø© + Ø­Ø§Ø³Ø¨Ø© ÙˆØ±Ø§Ø«ÙŠØ© + Ù…ØµØ§Ø¯Ø± Ù…ÙˆØ«ÙˆÙ‚Ø© + ØªØ­Ù„ÙŠÙ„ Ø¨ØµØ±ÙŠ
# ØªØµÙ…ÙŠÙ… ÙˆÙ‡ÙŠÙƒÙ„Ø©: Ø£Ù†Ø³ Ø§Ù„Ø¹Ø±Ø§ÙŠÙØ© | Ø¯Ù…Ø¬ ÙˆØªÙƒÙŠÙŠÙ: Gemini
# ===================================================================

import streamlit as st
from itertools import product
import collections
import pandas as pd
import numpy as np
import pickle
import os
import json
from datetime import datetime
from typing import List, Dict, Tuple
import plotly.express as px

# --- Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªÙˆÙØ± Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© ---
try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

try:
    import faiss
    from sentence_transformers import SentenceTransformer
    VECTOR_SEARCH_AVAILABLE = True
except ImportError:
    VECTOR_SEARCH_AVAILABLE = False

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø© ---
st.set_page_config(
    layout="wide",
    page_title="Ø§Ù„Ø¹Ø±Ù‘Ø§Ø¨ Ù„Ù„Ø¬ÙŠÙ†Ø§Øª V5.0",
    page_icon="ğŸ§¬",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': None,
        'Report a bug': None,
        'About': """
        # Ø§Ù„Ø¹Ø±Ù‘Ø§Ø¨ Ù„Ù„Ø¬ÙŠÙ†Ø§Øª V5.0
        Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø´Ø§Ù…Ù„Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© - Ø£Ø¯Ø§Ø© Ù…ØªÙƒØ§Ù…Ù„Ø© Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØ±Ø§Ø«Ø© ÙˆØ£Ù„ÙˆØ§Ù† Ø§Ù„Ø­Ù…Ø§Ù…
        """
    }
)

# --- 2. CSS Ù…Ø®ØµØµ Ù„Ù„ÙˆØ§Ø¬Ù‡Ø© ---
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(135deg, #667eea 0%, #764ba2 50%, #f093fb 100%);
        padding: 2rem;
        border-radius: 15px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
        box-shadow: 0 8px 32px rgba(0,0,0,0.1);
    }
    
    .metric-card {
        background: white;
        padding: 1.5rem;
        border-radius: 12px;
        box-shadow: 0 4px 12px rgba(0,0,0,0.1);
        border-left: 5px solid #667eea;
        margin-bottom: 1rem;
    }
    
    .info-box {
        background: linear-gradient(135deg, #f0f2f6 0%, #e8f5e8 100%);
        padding: 1.5rem;
        border-radius: 12px;
        border-left: 5px solid #28a745;
        margin: 1rem 0;
    }
    
    .warning-box {
        background: linear-gradient(135deg, #fff3cd 0%, #ffeaa7 100%);
        padding: 1.5rem;
        border-radius: 12px;
        border-left: 5px solid #ffc107;
        margin: 1rem 0;
    }
    
    .calculator-section {
        background: linear-gradient(135deg, #f8f9ff 0%, #e6f3ff 100%);
        padding: 2rem;
        border-radius: 15px;
        border: 1px solid #e0e6ed;
        margin: 1rem 0;
    }
    
    .stTabs [data-baseweb="tab-list"] {
        gap: 12px;
        background: rgba(255,255,255,0.1);
        padding: 8px;
        border-radius: 12px;
    }
    
    .stTabs [data-baseweb="tab"] {
        height: 60px;
        padding: 0 30px;
        border-radius: 8px;
        font-weight: 600;
    }
    
    .trusted-source {
        background: #f8f9fa;
        padding: 1rem;
        border-radius: 8px;
        border-left: 4px solid #007bff;
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

# --- 3. Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØ±Ø§Ø«ÙŠØ© ÙˆØ§Ù„Ù…ØµØ§Ø¯Ø± ---
GENE_DATA = {
    'B': {
        'display_name_ar': "Ø§Ù„Ù„ÙˆÙ† Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ", 'type_en': 'sex-linked',
        'alleles': { 'BA': {'name': 'Ø¢Ø´ Ø±ÙŠØ¯'}, '+': {'name': 'Ø£Ø²Ø±Ù‚/Ø£Ø³ÙˆØ¯'}, 'b': {'name': 'Ø¨Ù†ÙŠ'} },
        'dominance': ['BA', '+', 'b']
    },
    'd': {
        'display_name_ar': "Ø§Ù„ØªØ®ÙÙŠÙ", 'type_en': 'sex-linked',
        'alleles': { '+': {'name': 'Ø¹Ø§Ø¯ÙŠ (ØºÙŠØ± Ù…Ø®ÙÙ)'}, 'd': {'name': 'Ù…Ø®ÙÙ'} },
        'dominance': ['+', 'd']
    },
    'e': {
        'display_name_ar': "Ø£Ø­Ù…Ø± Ù…ØªÙ†Ø­ÙŠ", 'type_en': 'autosomal',
        'alleles': { '+': {'name': 'Ø¹Ø§Ø¯ÙŠ (ØºÙŠØ± Ø£Ø­Ù…Ø± Ù…ØªÙ†Ø­ÙŠ)'}, 'e': {'name': 'Ø£Ø­Ù…Ø± Ù…ØªÙ†Ø­ÙŠ'} },
        'dominance': ['+', 'e']
    },
    'C': {
        'display_name_ar': "Ø§Ù„Ù†Ù…Ø·", 'type_en': 'autosomal',
        'alleles': { 'CT': {'name': 'Ù†Ù…Ø· ØªÙŠ (Ù…Ø®Ù…Ù„ÙŠ)'}, 'C': {'name': 'ØªØ´ÙŠÙƒØ±'}, '+': {'name': 'Ø¨Ø§Ø± (Ø´Ø±ÙŠØ·)'}, 'c': {'name': 'Ø¨Ø¯ÙˆÙ† Ø´Ø±ÙŠØ·'} },
        'dominance': ['CT', 'C', '+', 'c']
    },
    'S': {
        'display_name_ar': "Ø§Ù„Ø§Ù†ØªØ´Ø§Ø± (Ø³Ø¨Ø±ÙŠØ¯)", 'type_en': 'autosomal',
        'alleles': { 'S': {'name': 'Ù…Ù†ØªØ´Ø± (Ø³Ø¨Ø±ÙŠØ¯)'}, '+': {'name': 'Ø¹Ø§Ø¯ÙŠ (ØºÙŠØ± Ù…Ù†ØªØ´Ø±)'} },
        'dominance': ['S', '+']
    }
}
GENE_ORDER = list(GENE_DATA.keys())
NAME_TO_SYMBOL_MAP = {
    gene: {info['name']: symbol for symbol, info in data['alleles'].items()}
    for gene, data in GENE_DATA.items()
}

TRUSTED_SOURCES = {
    'Ø¬ÙŠÙ†Ø§Øª ÙˆØ³Ù„Ø§Ù„Ø§Øª': [
        {'name': 'Pigeon Breeding: Genetics At Work', 'url': 'https://www.amazon.com/Pigeon-Breeding-Genetics-Work/dp/1888963098', 'description': 'ÙƒØªØ§Ø¨ Ø´Ø§Ù…Ù„ Ø¹Ù† ÙˆØ±Ø§Ø«Ø© Ø§Ù„Ø­Ù…Ø§Ù…'},
        {'name': "Ronald Huntley's Pigeon Genetics", 'url': 'http://www.huntley.pigeonwebsite.com/', 'description': 'Ù…ÙˆÙ‚Ø¹ Ø±ÙˆÙ†Ø§Ù„Ø¯ Ù‡Ø§Ù†ØªÙ„ÙŠ Ù„Ù„ÙˆØ±Ø§Ø«Ø©'},
    ],
    'Ø¬Ù…Ø¹ÙŠØ§Øª Ø±Ø³Ù…ÙŠØ©': [
        {'name': 'National Pigeon Association (NPA)', 'url': 'https://www.npausa.com/', 'description': 'Ø§Ù„Ø¬Ù…Ø¹ÙŠØ© Ø§Ù„ÙˆØ·Ù†ÙŠØ© Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠØ©'},
    ],
    'ØµØ­Ø© ÙˆØ¹Ù„Ø§Ø¬Ø§Øª': [
        {'name': 'Merck Veterinary Manual', 'url': 'https://www.merckvetmanual.com/poultry/pigeons-and-doves', 'description': 'Ø¯Ù„ÙŠÙ„ Ø§Ù„Ø·Ø¨ Ø§Ù„Ø¨ÙŠØ·Ø±ÙŠ'},
    ],
    'Ù…ØµØ§Ø¯Ø± Ø¹Ù„Ù…ÙŠØ©': [
        {'name': 'PubMed (Pigeon Genetics)', 'url': 'https://pubmed.ncbi.nlm.nih.gov/?term=pigeon+genetics', 'description': 'Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¹Ù„Ù…ÙŠØ©'},
    ]
}

# --- 4. Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¬Ù„Ø³Ø© Ø§Ù„Ù…Ø­Ø³Ù†Ø© ---
def initialize_session_state():
    """ØªÙ‡ÙŠØ¦Ø© Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø© Ù…Ø¹ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø´Ø§Ù…Ù„Ø©."""
    defaults = {
        "messages": [],
        "search_history": [],
        "calculation_history": [],
        "user_preferences": {
            "max_results": 10,
            "analysis_depth": "Ù…ØªÙˆØ³Ø·",
            "language_style": "Ø¹Ù„Ù…ÙŠ",
            "include_charts": True,
            "show_trusted_sources": True,
        },
        "session_stats": {
            "queries_count": 0,
            "successful_searches": 0,
            "charts_generated": 0,
            "calculations_performed": 0,
            "sources_referenced": 0
        },
    }
    for key, value in defaults.items():
        if key not in st.session_state:
            st.session_state[key] = value

# --- 5. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… ---
@st.cache_resource(show_spinner="Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©...")
def load_enhanced_resources():
    """ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø´Ø§Ù…Ù„Ø© Ù„Ù„Ø£Ø®Ø·Ø§Ø¡."""
    resources = {"status": "loading"}
    
    if VECTOR_SEARCH_AVAILABLE:
        vector_db_path = "pigeon_knowledge_base_v8.0.pkl"
        if os.path.exists(vector_db_path):
            try:
                with open(vector_db_path, "rb") as f:
                    resources["vector_db"] = pickle.load(f)
                resources["embedder"] = SentenceTransformer("sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
                resources["status"] = "ready"
            except Exception as e:
                st.error(f"Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…ØªØ¬Ù‡Ø§Øª: {e}")
                resources["status"] = "failed"
        else:
            st.warning("Ù…Ù„Ù Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© (vector_db.pkl) ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯.")
            resources["status"] = "no_db"

    else:
        resources["status"] = "vector_search_unavailable"
        
    return resources

@st.cache_resource(show_spinner="Ø¬Ø§Ø±ÙŠ ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ...")
def initialize_enhanced_gemini():
    """ØªÙ‡ÙŠØ¦Ø© Ù†Ù…ÙˆØ°Ø¬ Gemini Ù…Ø¹ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ø­Ø³Ù†Ø©."""
    if not GEMINI_AVAILABLE: return None
    api_key = st.secrets.get("GEMINI_API_KEY")
    if not api_key: return None
    
    try:
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-flash',
            generation_config={"temperature": 0.1, "max_output_tokens": 4096})
        return model
    except Exception as e:
        st.error(f"ÙØ´Ù„ ØªÙ‡ÙŠØ¦Ø© Gemini: {e}")
        return None

# --- 6. Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„ÙˆØ±Ø§Ø«ÙŠ Ø§Ù„Ù…Ø·ÙˆØ± ---
class EnhancedGeneticCalculator:
    def describe_phenotype(self, genotype_dict):
        phenotypes = {gene: "" for gene in GENE_ORDER}
        for gene_name, gt_part in genotype_dict.items():
            alleles = gt_part.replace('â€¢//', '').split('//')
            for dominant_allele in GENE_DATA[gene_name]['dominance']:
                if dominant_allele in alleles:
                    phenotypes[gene_name] = GENE_DATA[gene_name]['alleles'][dominant_allele]['name']
                    break
        
        if 'e//e' in genotype_dict.get('e', ''):
            phenotypes['B'] = 'Ø£Ø­Ù…Ø± Ù…ØªÙ†Ø­ÙŠ'
            phenotypes['C'] = ''
        
        if 'S' in genotype_dict.get('S', ''):
            if 'e//e' not in genotype_dict.get('e', ''):
                phenotypes['C'] = 'Ù…Ù†ØªØ´Ø± (Ø³Ø¨Ø±ÙŠØ¯)'
        
        sex = "Ø£Ù†Ø«Ù‰" if any('â€¢' in genotype_dict.get(g, '') for g, d in GENE_DATA.items() if d['type_en'] == 'sex-linked') else "Ø°ÙƒØ±"
        
        desc_parts = [phenotypes.get('B')]
        if phenotypes.get('d') == 'Ù…Ø®ÙÙ': desc_parts.append('Ù…Ø®ÙÙ')
        if phenotypes.get('C'): desc_parts.append(phenotypes.get('C'))
        
        gt_str_parts = [genotype_dict[gene].strip() for gene in GENE_ORDER]
        gt_str = " | ".join(gt_str_parts)
        final_phenotype = " ".join(filter(None, desc_parts))
        return f"{sex} {final_phenotype}", gt_str

    def calculate_detailed_genetics(self, parent_inputs):
        try:
            parent_genotypes = {}
            for parent in ['male', 'female']:
                gt_parts = []
                for gene in GENE_ORDER:
                    gene_info = GENE_DATA[gene]
                    visible_name = parent_inputs[parent].get(f'{gene}_visible')
                    hidden_name = parent_inputs[parent].get(f'{gene}_hidden', visible_name)
                    wild_type_symbol = next((s for s, n in gene_info['alleles'].items() if '+' in s), gene_info['dominance'][0])
                    visible_symbol = NAME_TO_SYMBOL_MAP[gene].get(visible_name, wild_type_symbol)
                    hidden_symbol = NAME_TO_SYMBOL_MAP[gene].get(hidden_name, wild_type_symbol)
                    
                    if gene_info['type_en'] == 'sex-linked' and parent == 'female':
                        gt_parts.append(f"â€¢//{visible_symbol}")
                    else:
                        alleles = sorted([visible_symbol, hidden_symbol], key=lambda x: gene_info['dominance'].index(x))
                        gt_parts.append(f"{alleles[0]}//{alleles[1]}")
                parent_genotypes[parent] = gt_parts

            def generate_gametes(genotype_parts, is_female):
                parts_for_product = []
                for i, gt_part in enumerate(genotype_parts):
                    gene_name = GENE_ORDER[i]
                    if GENE_DATA[gene_name]['type_en'] == 'sex-linked' and is_female:
                        parts_for_product.append([gt_part.replace('â€¢//','').strip()])
                    else:
                        parts_for_product.append(gt_part.split('//'))
                return list(product(*parts_for_product))

            male_gametes = generate_gametes(parent_genotypes['male'], is_female=False)
            female_gametes = generate_gametes(parent_genotypes['female'], is_female=True)
            
            offspring_counts = collections.Counter()
            for m_gamete in male_gametes:
                for f_gamete in female_gametes:
                    son_dict, daughter_dict = {}, {}
                    for i, gene in enumerate(GENE_ORDER):
                        alleles = sorted([m_gamete[i], f_gamete[i]], key=lambda x: GENE_DATA[gene]['dominance'].index(x))
                        if GENE_DATA[gene]['type_en'] == 'sex-linked':
                            son_dict[gene] = f"{alleles[0]}//{alleles[1]}"
                            daughter_dict[gene] = f"â€¢//{m_gamete[i]}"
                        else:
                            gt_part = f"{alleles[0]}//{alleles[1]}"
                            son_dict[gene] = gt_part
                            daughter_dict[gene] = gt_part
                    offspring_counts[self.describe_phenotype(son_dict)] += 1
                    offspring_counts[self.describe_phenotype(daughter_dict)] += 1
            
            total_offspring = sum(offspring_counts.values())
            sex_dist = {'Ø°ÙƒØ±': sum(c for (p,g),c in offspring_counts.items() if 'Ø°ÙƒØ±' in p), 'Ø£Ù†Ø«Ù‰': sum(c for (p,g),c in offspring_counts.items() if 'Ø£Ù†Ø«Ù‰' in p)}
            
            return {
                'results': offspring_counts,
                'total_offspring': total_offspring,
                'sex_distribution': sex_dist,
            }
        except Exception as e:
            return {'error': f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­Ø³Ø§Ø¨: {str(e)}"}

# --- 7. Ø§Ù„Ø¨Ø­Ø« ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ØªÙ‚Ø¯Ù… ---
def enhanced_search_knowledge(query: str, resources: dict, top_k: int = 5) -> List[Dict]:
    if not resources.get("vector_db") or not resources.get("embedder"):
        return []
    try:
        index = resources["vector_db"]["index"]
        chunks = resources["vector_db"]["chunks"]
        query_embedding = resources["embedder"].encode([query])
        distances, indices = index.search(np.array(query_embedding, dtype=np.float32), top_k)
        return [{"content": chunks[idx], "score": 1 / (1 + dist)} for dist, idx in zip(distances[0], indices[0]) if idx < len(chunks)]
    except Exception as e:
        st.warning(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ: {e}")
        return []

def get_relevant_trusted_sources(query: str) -> List[Dict]:
    relevant_sources = []
    # ... (Ù…Ù†Ø·Ù‚ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…ÙˆØ«ÙˆÙ‚Ø©)
    return relevant_sources

# --- 8. Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø®Ø¨ÙŠØ± Ø§Ù„Ù…ØªØ·ÙˆØ± ---
def ultimate_expert_agent(query: str, resources: dict, preferences: dict) -> Dict:
    st.session_state.session_stats["queries_count"] += 1
    
    if not resources.get("model"):
        # Fallback response if AI model is not available
        return {"answer": "âŒ Ù†Ø¸Ø§Ù… Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ØºÙŠØ± Ù…ØªØ§Ø­. ÙŠØ±Ø¬Ù‰ Ø¥Ø¹Ø¯Ø§Ø¯ Ù…ÙØªØ§Ø­ API.", "confidence": 0.1}

    with st.spinner("ğŸ” Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©..."):
        search_results = enhanced_search_knowledge(query, resources, top_k=preferences.get("max_results", 5))

    context_text = "\n\n---\n\n".join([r['content'] for r in search_results])
    
    prompt = f"""
Ø£Ù†Øª "Ø§Ù„Ø¹Ø±Ù‘Ø§Ø¨ V5.0 - Ø§Ù„Ø®Ø¨ÙŠØ± Ø§Ù„Ø´Ø§Ù…Ù„".
Ø£Ø¬Ø¨ Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ø¯Ù‚Ø© ÙˆØ¹Ù„Ù…ÙŠØ© Ø¨Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„ØªØ§Ù„ÙŠ.

Ø§Ù„Ø³ÙŠØ§Ù‚:
{context_text}

Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:
{query}

Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„:
"""
    with st.spinner("ğŸ§  Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªÙ†ØªØ§Ø¬ÙŠ Ø§Ù„Ù…ØªÙ‚Ø¯Ù…..."):
        try:
            ai_response = resources["model"].generate_content(prompt)
            final_answer = ai_response.text
            confidence = np.mean([r['score'] for r in search_results]) if search_results else 0.3
            return {"answer": final_answer, "confidence": confidence, "sources": search_results}
        except Exception as e:
            return {"answer": f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {str(e)}", "confidence": 0.2, "sources": search_results}

# --- 9. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø´Ø§Ù…Ù„Ø© ---
def main():
    initialize_session_state()
    resources = load_enhanced_resources()
    model = initialize_enhanced_gemini()
    resources["model"] = model

    st.markdown('<div class="main-header"><h1>ğŸš€ Ø§Ù„Ø¹Ø±Ù‘Ø§Ø¨ Ù„Ù„Ø¬ÙŠÙ†Ø§Øª V5.0</h1><p><strong>Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø´Ø§Ù…Ù„Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©</strong></p></div>', unsafe_allow_html=True)
    
    tab1, tab2, tab3 = st.tabs(["ğŸ’¬ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø°ÙƒÙŠØ©", "ğŸ§¬ Ø§Ù„Ø­Ø§Ø³Ø¨Ø© Ø§Ù„ÙˆØ±Ø§Ø«ÙŠØ©", "âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØ§Ù„ØªØ§Ø±ÙŠØ®"])

    with tab1:
        st.subheader("ğŸ¤– ØªØ­Ø¯Ø« Ù…Ø¹ Ø§Ù„Ø®Ø¨ÙŠØ± Ø§Ù„ÙˆØ±Ø§Ø«ÙŠ")
        chat_container = st.container(height=500)
        for message in st.session_state.messages:
            with chat_container.chat_message(message["role"]):
                st.markdown(message["content"])
        
        if prompt := st.chat_input("Ù…Ø«Ø§Ù„: Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø¬ÙŠÙ†Ø§Øª Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„Ø© Ø¹Ù† Ø§Ù„Ù„ÙˆÙ† Ø§Ù„Ø¨Ù†ÙŠØŸ"):
            st.session_state.messages.append({"role": "user", "content": prompt})
            chat_container.chat_message("user").markdown(prompt)
            
            with chat_container.chat_message("assistant"):
                response_data = ultimate_expert_agent(prompt, resources, st.session_state.user_preferences)
                st.markdown(response_data["answer"])
                st.session_state.messages.append({"role": "assistant", "content": response_data["answer"]})

    with tab2:
        st.subheader("ğŸ§® Ø§Ù„Ø­Ø§Ø³Ø¨Ø© Ø§Ù„ÙˆØ±Ø§Ø«ÙŠØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©")
        with st.container(border=True):
            col1, col2 = st.columns(2)
            parent_inputs = {'male': {}, 'female': {}}
            
            with col1:
                st.markdown("#### â™‚ï¸ **Ø§Ù„Ø°ÙƒØ± (Ø§Ù„Ø£Ø¨)**")
                for gene, data in GENE_DATA.items():
                    choices = ["(Ø§Ø®ØªØ±)"] + [v['name'] for v in data['alleles'].values()]
                    parent_inputs['male'][f'{gene}_visible'] = st.selectbox(f"**{data['display_name_ar']}** (Ø§Ù„Ø¸Ø§Ù‡Ø±):", choices, key=f"calc_male_{gene}_visible")
                    parent_inputs['male'][f'{gene}_hidden'] = st.selectbox(f"**{data['display_name_ar']}** (Ø§Ù„Ø®ÙÙŠ):", choices, key=f"calc_male_{gene}_hidden")
            
            with col2:
                st.markdown("#### â™€ï¸ **Ø§Ù„Ø£Ù†Ø«Ù‰ (Ø§Ù„Ø£Ù…)**")
                for gene, data in GENE_DATA.items():
                    choices = ["(Ø§Ø®ØªØ±)"] + [v['name'] for v in data['alleles'].values()]
                    parent_inputs['female'][f'{gene}_visible'] = st.selectbox(f"**{data['display_name_ar']}** (Ø§Ù„Ø¸Ø§Ù‡Ø±):", choices, key=f"calc_female_{gene}_visible")
                    if data['type_en'] != 'sex-linked':
                        parent_inputs['female'][f'{gene}_hidden'] = st.selectbox(f"**{data['display_name_ar']}** (Ø§Ù„Ø®ÙÙŠ):", choices, key=f"calc_female_{gene}_hidden")
                    else:
                        st.info(f"**{data['display_name_ar']}**: Ø§Ù„Ø¥Ù†Ø§Ø« Ù„Ø¯ÙŠÙ‡Ø§ Ø£Ù„ÙŠÙ„ ÙˆØ§Ø­Ø¯ ÙÙ‚Ø·.", icon="â„¹ï¸")
                        parent_inputs['female'][f'{gene}_hidden'] = parent_inputs['female'][f'{gene}_visible']

            if st.button("ğŸš€ Ø§Ø­Ø³Ø¨ Ø§Ù„Ù†ØªØ§Ø¦Ø¬", use_container_width=True, type="primary"):
                if not all(val != "(Ø§Ø®ØªØ±)" for val in [parent_inputs['male']['B_visible'], parent_inputs['female']['B_visible']]):
                    st.error("âš ï¸ ÙŠØ±Ø¬Ù‰ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù„ÙˆÙ† Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„ÙƒÙ„Ø§ Ø§Ù„ÙˆØ§Ù„Ø¯ÙŠÙ†.")
                else:
                    calculator = EnhancedGeneticCalculator()
                    result_data = calculator.calculate_detailed_genetics(parent_inputs)
                    st.session_state.calculation_history.append(result_data)
                    st.session_state.session_stats["calculations_performed"] += 1

        # Ø¹Ø±Ø¶ Ø¢Ø®Ø± Ù†ØªÙŠØ¬Ø© Ø­Ø³Ø§Ø¨
        if st.session_state.calculation_history:
            last_calc = st.session_state.calculation_history[-1]
            st.subheader("ğŸ“Š Ø£Ø­Ø¯Ø« Ø§Ù„Ù†ØªØ§Ø¦Ø¬")
            if 'error' in last_calc:
                st.error(last_calc['error'])
            else:
                df_results = pd.DataFrame([{'Ø§Ù„Ù†Ù…Ø· Ø§Ù„Ø¸Ø§Ù‡Ø±ÙŠ': p, 'Ø§Ù„Ù†Ù…Ø· Ø§Ù„ÙˆØ±Ø§Ø«ÙŠ': g, 'Ø§Ù„Ù†Ø³Ø¨Ø© %': f"{(c/last_calc['total_offspring'])*100:.1f}%"} for (p, g), c in last_calc['results'].items()])
                st.dataframe(df_results, use_container_width=True)
                
                fig = px.pie(values=list(last_calc['color_distribution'].values()), names=list(last_calc['color_distribution'].keys()), title="ØªÙˆØ²ÙŠØ¹ Ø§Ù„Ø£Ù„ÙˆØ§Ù†")
                st.plotly_chart(fig, use_container_width=True)

    with tab3:
        st.subheader("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØªØ§Ø±ÙŠØ® Ø§Ù„Ø¬Ù„Ø³Ø©")
        st.markdown("---")
        with st.expander("ğŸ”§ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨Ø­Ø« ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„"):
            prefs = st.session_state.user_preferences
            prefs['max_results'] = st.slider("Ø¹Ø¯Ø¯ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø«", 5, 20, prefs['max_results'])
            prefs['analysis_depth'] = st.select_slider("Ø¹Ù…Ù‚ Ø§Ù„ØªØ­Ù„ÙŠÙ„", ["Ø¨Ø³ÙŠØ·", "Ù…ØªÙˆØ³Ø·", "Ø¹Ù…ÙŠÙ‚"], value=prefs['analysis_depth'])
            prefs['language_style'] = st.radio("Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ù„ØºØ©", ["Ø¹Ù„Ù…ÙŠ", "Ù…Ø¨Ø³Ø·", "ØªÙ‚Ù†ÙŠ"], index=["Ø¹Ù„Ù…ÙŠ", "Ù…Ø¨Ø³Ø·", "ØªÙ‚Ù†ÙŠ"].index(prefs['language_style']))
            prefs['include_charts'] = st.toggle("ØªØ¶Ù…ÙŠÙ† Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©", value=prefs['include_charts'])
        
        with st.expander("ğŸ“œ ØªØ§Ø±ÙŠØ® Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª"):
            if st.session_state.calculation_history:
                for i, calc in enumerate(reversed(st.session_state.calculation_history)):
                    st.json(calc, expanded=False)
            else:
                st.info("Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØªØ§Ø±ÙŠØ® Ø­Ø³Ø§Ø¨Ø§Øª Ø¨Ø¹Ø¯.")

if __name__ == "__main__":
    main()
