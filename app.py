# ===================================================================
# ğŸš€ Ø§Ù„Ø¹Ø±Ù‘Ø§Ø¨ Ù„Ù„Ø¬ÙŠÙ†Ø§Øª V56.0 - Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø®Ø¨ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
# ÙŠØ¬Ù…Ø¹ Ø¨ÙŠÙ† Ø°Ø§ÙƒØ±Ø© Ø§Ù„ÙƒØªØ§Ø¨ Ø§Ù„ÙƒØ§Ù…Ù„Ø© ÙˆØ³Ø±Ø¹Ø© Ø§Ù„Ø¨Ø« Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ù„Ù„Ø¥Ø¬Ø§Ø¨Ø©
# ===================================================================

import streamlit as st
from itertools import product
import collections
import pandas as pd
import google.generativeai as genai
import json
import os
import time
from datetime import datetime

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ---
st.set_page_config(layout="wide", page_title="Ø§Ù„Ø¹Ø±Ù‘Ø§Ø¨ Ù„Ù„Ø¬ÙŠÙ†Ø§Øª - Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø®Ø¨ÙŠØ±")

# --- 2. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±ÙŠØ© Ø¹Ù†Ø¯ Ø§Ù„Ø­Ø§Ø¬Ø© ---
@st.cache_resource
def import_langchain():
    """
    Imports heavy langchain libraries only when needed.
    """
    from langchain_google_genai import GoogleGenerativeAIEmbeddings
    from langchain_community.vectorstores import FAISS
    from langchain_google_genai import ChatGoogleGenerativeAI
    from langchain.chains import RetrievalQA
    from langchain.prompts import PromptTemplate
    return GoogleGenerativeAIEmbeddings, FAISS, ChatGoogleGenerativeAI, RetrievalQA, PromptTemplate

# --- 3. Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØ±Ø§Ø«ÙŠØ© (Ù„Ù„Ø­Ø§Ø³Ø¨Ø©) ---
GENE_DATA = {
    'B': {
        'display_name_ar': "Ø§Ù„Ù„ÙˆÙ† Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ", 'type_en': 'sex-linked',
        'alleles': { 'BA': {'name': 'Ø¢Ø´ Ø±ÙŠØ¯'}, '+': {'name': 'Ø£Ø²Ø±Ù‚/Ø£Ø³ÙˆØ¯'}, 'b': {'name': 'Ø¨Ù†ÙŠ'} },
        'dominance': ['BA', '+', 'b']
    },
    'd': {
        'display_name_ar': "Ø§Ù„ØªØ®ÙÙŠÙ", 'type_en': 'sex-linked',
        'alleles': { '+': {'name': 'Ø¹Ø§Ø¯ÙŠ (ØºÙŠØ± Ù…Ø®ÙÙ)'}, 'd': {'name': 'Ù…Ø®ÙÙ'} },
        'dominance': ['+', 'd']
    },
    'e': {
        'display_name_ar': "Ø£Ø­Ù…Ø± Ù…ØªÙ†Ø­ÙŠ", 'type_en': 'autosomal',
        'alleles': { '+': {'name': 'Ø¹Ø§Ø¯ÙŠ (ØºÙŠØ± Ø£Ø­Ù…Ø± Ù…ØªÙ†Ø­ÙŠ)'}, 'e': {'name': 'Ø£Ø­Ù…Ø± Ù…ØªÙ†Ø­ÙŠ'} },
        'dominance': ['+', 'e']
    },
    'C': {
        'display_name_ar': "Ø§Ù„Ù†Ù…Ø·", 'type_en': 'autosomal',
        'alleles': { 'CT': {'name': 'Ù†Ù…Ø· ØªÙŠ (Ù…Ø®Ù…Ù„ÙŠ)'}, 'C': {'name': 'ØªØ´ÙŠÙƒØ±'}, '+': {'name': 'Ø¨Ø§Ø± (Ø´Ø±ÙŠØ·)'}, 'c': {'name': 'Ø¨Ø¯ÙˆÙ† Ø´Ø±ÙŠØ·'} },
        'dominance': ['CT', 'C', '+', 'c']
    },
    'S': {
        'display_name_ar': "Ø§Ù„Ø§Ù†ØªØ´Ø§Ø± (Ø³Ø¨Ø±ÙŠØ¯)", 'type_en': 'autosomal',
        'alleles': { 'S': {'name': 'Ù…Ù†ØªØ´Ø± (Ø³Ø¨Ø±ÙŠØ¯)'}, '+': {'name': 'Ø¹Ø§Ø¯ÙŠ (ØºÙŠØ± Ù…Ù†ØªØ´Ø±)'} },
        'dominance': ['S', '+']
    }
}
GENE_ORDER = list(GENE_DATA.keys())
NAME_TO_SYMBOL_MAP = {
    gene: {info['name']: symbol for symbol, info in data['alleles'].items()}
    for gene, data in GENE_DATA.items()
}

# --- 4. Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„ÙˆØ±Ø§Ø«ÙŠ (Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ±) ---
class GeneticCalculator:
    def describe_phenotype(self, genotype_dict):
        phenotypes = {gene: "" for gene in GENE_ORDER}
        for gene_name, gt_part in genotype_dict.items():
            alleles = gt_part.replace('â€¢//', '').split('//')
            for dominant_allele in GENE_DATA[gene_name]['dominance']:
                if dominant_allele in alleles:
                    phenotypes[gene_name] = GENE_DATA[gene_name]['alleles'][dominant_allele]['name']
                    break
        if 'e//e' in genotype_dict.get('e', ''):
            phenotypes['B'] = 'Ø£Ø­Ù…Ø± Ù…ØªÙ†Ø­ÙŠ'; phenotypes['C'] = ''
        if 'S' in genotype_dict.get('S', ''):
            if 'e//e' not in genotype_dict.get('e', ''):
                phenotypes['C'] = 'Ù…Ù†ØªØ´Ø± (Ø³Ø¨Ø±ÙŠØ¯)'
        sex = "Ø£Ù†Ø«Ù‰" if any('â€¢' in genotype_dict.get(g, '') for g, d in GENE_DATA.items() if d['type_en'] == 'sex-linked') else "Ø°ÙƒØ±"
        desc_parts = [phenotypes.get('B')]
        if phenotypes.get('C'): desc_parts.append(phenotypes.get('C'))
        gt_str_parts = [genotype_dict[gene].strip() for gene in GENE_ORDER]
        gt_str = " | ".join(gt_str_parts)
        final_phenotype = " ".join(filter(None, desc_parts))
        return f"{sex} {final_phenotype}", gt_str

def predict_genetics_final(parent_inputs):
    calculator = GeneticCalculator()
    parent_genotypes = {}
    for parent in ['male', 'female']:
        gt_parts = []
        for gene in GENE_ORDER:
            gene_info = GENE_DATA[gene]
            visible_name = parent_inputs[parent].get(f'{gene}_visible')
            hidden_name = parent_inputs[parent].get(f'{gene}_hidden', visible_name)
            wild_type_symbol = next((s for s, n in gene_info['alleles'].items() if '+' in s or 'âº' in s), gene_info['dominance'][0])
            visible_symbol = NAME_TO_SYMBOL_MAP[gene].get(visible_name, wild_type_symbol)
            hidden_symbol = NAME_TO_SYMBOL_MAP[gene].get(hidden_name, visible_symbol)
            if gene_info['type_en'] == 'sex-linked' and parent == 'female':
                gt_parts.append(f"â€¢//{visible_symbol}")
            else:
                alleles = sorted([visible_symbol, hidden_symbol], key=lambda x: gene_info['dominance'].index(x))
                gt_parts.append(f"{alleles[0]}//{alleles[1]}")
        parent_genotypes[parent] = gt_parts
    def generate_gametes(genotype_parts, is_female):
        parts_for_product = []
        for i, gt_part in enumerate(genotype_parts):
            gene_name = GENE_ORDER[i]
            if GENE_DATA[gene_name]['type_en'] == 'sex-linked' and is_female:
                parts_for_product.append([gt_part.replace('â€¢//','').strip()])
            else:
                parts_for_product.append(gt_part.split('//'))
        return list(product(*parts_for_product))
    male_gametes = generate_gametes(parent_genotypes['male'], is_female=False)
    female_gametes = generate_gametes(parent_genotypes['female'], is_female=True)
    offspring_counts = collections.Counter()
    for m_gamete in male_gametes:
        for f_gamete in female_gametes:
            son_dict, daughter_dict = {}, {}
            for i, gene in enumerate(GENE_ORDER):
                alleles = sorted([m_gamete[i], f_gamete[i]], key=lambda x: GENE_DATA[gene]['dominance'].index(x))
                if GENE_DATA[gene]['type_en'] == 'sex-linked':
                    son_dict[gene], daughter_dict[gene] = f"{alleles[0]}//{alleles[1]}", f"â€¢//{m_gamete[i]}"
                else:
                    gt_part = f"{alleles[0]}//{alleles[1]}"
                    son_dict[gene], daughter_dict[gene] = gt_part, gt_part
            offspring_counts[calculator.describe_phenotype(son_dict)] += 1
            offspring_counts[calculator.describe_phenotype(daughter_dict)] += 1
    return offspring_counts

# --- 5. ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ø®Ø¨ÙŠØ± (Agent) ---
@st.cache_resource
def load_knowledge_base():
    """
    ØªØ­Ù…ÙŠÙ„ Ø°Ø§ÙƒØ±Ø© Ø§Ù„ÙˆÙƒÙŠÙ„ (Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØ¬Ù‡Ø©) Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª.
    """
    try:
        GoogleGenerativeAIEmbeddings, FAISS, _, _, _ = import_langchain()
        if "GEMINI_API_KEY" not in st.secrets:
            return None, "Ù…ÙØªØ§Ø­ Google API ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ø§Ù„Ø£Ø³Ø±Ø§Ø± (Secrets)."
        genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
        embeddings = GoogleGenerativeAIEmbeddings(model="models/embedding-001")
        db_path = "faiss_index_pigeon_genetics"
        if not os.path.exists(db_path):
            return None, f"Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø¬Ù„Ø¯ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª '{db_path}'. ÙŠØ±Ø¬Ù‰ Ø§ØªØ¨Ø§Ø¹ Ø¯Ù„ÙŠÙ„ Ø§Ù„ØªØ­Ø¯ÙŠØ«."
        vector_db = FAISS.load_local(db_path, embeddings, allow_dangerous_deserialization=True)
        return vector_db, None
    except Exception as e:
        return None, f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©: {e}"

def ask_expert_agent_stream(query, db):
    """
    ØªØ¨Ø« Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø¨Ø§Ø´Ø±Ø© ÙƒÙ„Ù…Ø© Ø¨ÙƒÙ„Ù…Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø°Ø§ÙƒØ±Ø© Ø§Ù„ÙƒØªØ§Ø¨.
    """
    try:
        _, _, ChatGoogleGenerativeAI, _, PromptTemplate = import_langchain()
        
        llm = ChatGoogleGenerativeAI(model="gemini-1.5-flash", temperature=0.3)
        
        # 1. Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø°Ø§Øª Ø§Ù„ØµÙ„Ø© ÙÙŠ Ø§Ù„ÙƒØªØ§Ø¨
        retriever = db.as_retriever(search_type="similarity", search_kwargs={"k": 4})
        relevant_docs = retriever.get_relevant_documents(query)
        
        context = ""
        for i, doc in enumerate(relevant_docs):
            context += f"Ù…ØµØ¯Ø± {i+1}:\n{doc.page_content}\n\n"

        # 2. Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø¨Ø±ÙˆÙ…Ø¨Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
        template = """
        Ø£Ù†Øª "Ø§Ù„Ø¹Ø±Ù‘Ø§Ø¨ Ø§Ù„Ø°ÙƒÙŠ"ØŒ Ø®Ø¨ÙŠØ± Ø¹Ø§Ù„Ù…ÙŠ ÙÙŠ ÙˆØ±Ø§Ø«Ø© Ø§Ù„Ø­Ù…Ø§Ù…. Ù…Ù‡Ù…ØªÙƒ Ù‡ÙŠ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø¨Ø¯Ù‚Ø© ÙˆØ¹Ù…Ù‚ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªÙˆÙØ±Ø© ÙÙŠ Ø§Ù„Ù…ØµØ§Ø¯Ø± ÙÙ‚Ø·.
        
        **Ø§Ù„Ù…ØµØ§Ø¯Ø± Ù…Ù† Ø§Ù„ÙƒØªØ§Ø¨:**
        ---
        {context}
        ---

        **Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:** {question}

        **ØªØ¹Ù„ÙŠÙ…Ø§Øª:**
        1. Ø£Ø¬Ø¨ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø£Ø³Ù„ÙˆØ¨ Ø¹Ù„Ù…ÙŠ ÙˆÙ…ÙØµÙ„.
        2. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…ØªÙˆÙØ±Ø© ÙÙ‚Ø·. Ù„Ø§ ØªØ®ØªØ±Ø¹ Ø£ÙŠ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª.
        3. Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…ØµØ§Ø¯Ø± Ù„Ø§ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø¥Ø¬Ø§Ø¨Ø© ÙˆØ§Ø¶Ø­Ø©ØŒ Ù‚Ù„ "Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…ØªÙˆÙØ±Ø© ÙÙŠ Ø§Ù„Ù…ØµØ¯Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ Ù„Ø§ ØªØ¬ÙŠØ¨ Ø¹Ù„Ù‰ Ù‡Ø°Ø§ Ø§Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø´ÙƒÙ„ Ù…Ø¨Ø§Ø´Ø±ØŒ ÙˆÙ„ÙƒÙ† ÙŠÙ…ÙƒÙ† Ø§Ø³ØªÙ†ØªØ§Ø¬ Ù…Ø§ ÙŠÙ„ÙŠ...".
        4. Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø³Ø¤Ø§Ù„ ØªØ±Ø­ÙŠØ¨Ø§Ù‹ Ø£Ùˆ Ø¹Ø§Ù…Ø§Ù‹ Ø¬Ø¯Ø§Ù‹ØŒ Ø£Ø¬Ø¨ Ø¨Ø´ÙƒÙ„ ÙˆØ¯ÙŠ ÙˆÙ…Ø®ØªØµØ±.

        **Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø§Ù„Ù…ÙØµÙ„Ø©:**
        """
        
        prompt = PromptTemplate(template=template, input_variables=["context", "question"])
        
        chain = prompt | llm
        
        # 3. Ø¨Ø« Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù…Ø¨Ø§Ø´Ø±Ø©
        for chunk in chain.stream({"context": context, "question": query}):
            yield chunk.content

    except Exception as e:
        yield f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ØªÙ‚Ù†ÙŠ: {str(e)[:200]}..."

# --- 6. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ ---
st.title("ğŸ•Šï¸ Ø§Ù„Ø¹Ø±Ù‘Ø§Ø¨ Ù„Ù„Ø¬ÙŠÙ†Ø§Øª (V56 - Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø®Ø¨ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ)")

vector_db, error_message = load_knowledge_base()

tab1, tab2 = st.tabs(["ğŸ¤– Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø®Ø¨ÙŠØ±", "ğŸ§¬ Ø§Ù„Ø­Ø§Ø³Ø¨Ø© Ø§Ù„ÙˆØ±Ø§Ø«ÙŠØ©"])

with tab1:
    st.header("ğŸ’¬ ØªØ­Ø¯Ø« Ù…Ø¹ Ø§Ù„Ø®Ø¨ÙŠØ±")
    
    if error_message:
        st.error(f"**Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©:** {error_message}")
        st.warning("Ù„Ù† ÙŠØªÙ…ÙƒÙ† Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø®Ø¨ÙŠØ± Ù…Ù† Ø§Ù„Ø¹Ù…Ù„ Ø­ØªÙ‰ ÙŠØªÙ… Ø­Ù„ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø´ÙƒÙ„Ø©.")
    elif vector_db is None:
        st.warning("Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø±...")
    else:
        st.success("âœ… Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø¬Ø§Ù‡Ø²Ø©. ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„Ø¢Ù† Ø·Ø±Ø­ Ø£ÙŠ Ø³Ø¤Ø§Ù„ Ø­ÙˆÙ„ Ù…Ø­ØªÙˆÙ‰ Ø§Ù„ÙƒØªØ§Ø¨.")
        
        if "messages" not in st.session_state:
            st.session_state.messages = []

        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

        if prompt := st.chat_input("Ù…Ø«Ø§Ù„: Ø§Ø´Ø±Ø­ Ù„ÙŠ Ø¹Ù† Ø¬ÙŠÙ† Ø§Ù„Ø£ÙˆØ¨Ø§Ù„..."):
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            with st.chat_message("assistant"):
                response_container = st.empty()
                full_response = response_container.write_stream(ask_expert_agent_stream(prompt, vector_db))
            
            st.session_state.messages.append({"role": "assistant", "content": full_response})

with tab2:
    st.header("ğŸ§¬ Ø§Ù„Ø­Ø§Ø³Ø¨Ø© Ø§Ù„ÙˆØ±Ø§Ø«ÙŠØ© Ø§Ù„Ø³Ø±ÙŠØ¹Ø©")
    parent_inputs = {'male': {}, 'female': {}}
    input_col, result_col = st.columns([2, 3])
    with input_col:
        st.subheader("ğŸ“ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
        col1, col2 = st.columns(2)
        with col1:
            st.write("**â™‚ï¸ Ø§Ù„Ø°ÙƒØ± (Ø§Ù„Ø£Ø¨)**")
            for gene, data in GENE_DATA.items():
                with st.expander(f"{data['display_name_ar']}"):
                    choices = ["(Ù„Ø§ Ø§Ø®ØªÙŠØ§Ø±)"] + [v['name'] for v in data['alleles'].values()]
                    parent_inputs['male'][f'{gene}_visible'] = st.selectbox("Ø§Ù„ØµÙØ© Ø§Ù„Ø¸Ø§Ù‡Ø±ÙŠØ©", choices, key=f"male_{gene}_visible")
                    parent_inputs['male'][f'{gene}_hidden'] = st.selectbox("Ø§Ù„ØµÙØ© Ø§Ù„Ø®ÙÙŠØ©", choices, key=f"male_{gene}_hidden")
        with col2:
            st.write("**â™€ï¸ Ø§Ù„Ø£Ù†Ø«Ù‰ (Ø§Ù„Ø£Ù…)**")
            for gene, data in GENE_DATA.items():
                with st.expander(f"{data['display_name_ar']}"):
                    choices = ["(Ù„Ø§ Ø§Ø®ØªÙŠØ§Ø±)"] + [v['name'] for v in data['alleles'].values()]
                    parent_inputs['female'][f'{gene}_visible'] = st.selectbox("Ø§Ù„ØµÙØ© Ø§Ù„Ø¸Ø§Ù‡Ø±ÙŠØ©", choices, key=f"female_{gene}_visible")
                    if data['type_en'] != 'sex-linked':
                        parent_inputs['female'][f'{gene}_hidden'] = st.selectbox("Ø§Ù„ØµÙØ© Ø§Ù„Ø®ÙÙŠØ©", choices, key=f"female_{gene}_hidden")
                    else:
                        st.info("Ù„Ø§ ÙŠÙˆØ¬Ø¯ ØµÙØ© Ø®ÙÙŠØ©")
                        parent_inputs['female'][f'{gene}_hidden'] = parent_inputs['female'][f'{gene}_visible']
    with result_col:
        st.subheader("ğŸ“Š Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…ØªÙˆÙ‚Ø¹Ø©")
        if st.button("âš¡ Ø§Ø­Ø³Ø¨ Ø§Ù„Ø¢Ù†", use_container_width=True, type="primary"):
            if not all([parent_inputs['male'].get('B_visible') != "(Ù„Ø§ Ø§Ø®ØªÙŠØ§Ø±)", parent_inputs['female'].get('B_visible') != "(Ù„Ø§ Ø§Ø®ØªÙŠØ§Ø±)"]):
                st.error("âš ï¸ Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù„ÙˆÙ† Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„ÙƒÙ„Ø§ Ø§Ù„ÙˆØ§Ù„Ø¯ÙŠÙ†.")
            else:
                with st.spinner("ğŸ§® Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø­Ø³Ø§Ø¨..."):
                    results = predict_genetics_final(parent_inputs)
                    total = sum(results.values())
                    st.success(f"âœ… ØªÙ… Ø­Ø³Ø§Ø¨ {total} ØªØ±ÙƒÙŠØ¨Ø©!")
                    df_results = pd.DataFrame([{'Ø§Ù„Ù†Ù…Ø· Ø§Ù„Ø¸Ø§Ù‡Ø±ÙŠ': p, 'Ø§Ù„Ù†Ù…Ø· Ø§Ù„ÙˆØ±Ø§Ø«ÙŠ': g, 'Ø§Ù„Ù†Ø³Ø¨Ø© %': f"{(c/total)*100:.1f}%"} for (p, g), c in results.items()])
                    st.dataframe(df_results, use_container_width=True)
                    chart_data = df_results.set_index('Ø§Ù„Ù†Ù…Ø· Ø§Ù„Ø¸Ø§Ù‡Ø±ÙŠ')['Ø§Ù„Ù†Ø³Ø¨Ø© %'].str.rstrip('%').astype('float')
                    st.bar_chart(chart_data)
