# ===================================================================
# ๐ ุงูุนุฑูุงุจ ููุฌููุงุช V2.0 - ูููู ุจุญุซู ุฐูู ูุญุณูู
# ุจููุฒุงุช ูุชูุฏูุฉ: ุชุญููู ูุชุนุฏุฏ ุงููุณุชููุงุชุ ุฐุงูุฑุฉ ูุญุงุฏุซุฉุ ุชุตุฏูุฑ ุงููุชุงุฆุฌ
# ===================================================================

import streamlit as st
from itertools import product
import collections
import pandas as pd
import google.generativeai as genai
import faiss
import numpy as np
import pickle
import os
import json
from datetime import datetime
import plotly.express as px
import plotly.graph_objects as go
from typing import List, Dict, Tuple
import re

# --- 1. ุฅุนุฏุงุฏุงุช ุงูุตูุญุฉ ุงููุญุณููุฉ ---
st.set_page_config(
    layout="wide", 
    page_title="ุงูุนุฑูุงุจ ููุฌููุงุช V2.0",
    page_icon="๐งฌ",
    initial_sidebar_state="expanded"
)

# --- 2. ูุฆุงุช ุงูุฃุณุฆูุฉ ุงูุฐููุฉ ---
QUESTION_CATEGORIES = {
    "basic": ["ูุง ูู", "ูุง ูู", "ุชุนุฑูู", "ูุนูู"],
    "genetic_inheritance": ["ูุฑุงุซุฉ", "ุฌูู", "ูุฑูููุณูู", "ุฏู ุงู ุงูู", "DNA"],
    "breeding": ["ุชุฑุจูุฉ", "ุชุฒุงูุฌ", "ุงูุชุงุฌ", "ุชุญุณูู"],
    "colors": ["ููู", "ุฃููุงู", "ุชูููู", "ุตุจุบุฉ"],
    "diseases": ["ูุฑุถ", "ุฃูุฑุงุถ", "ุนูุงุฌ", "ุตุญุฉ"],
    "analysis": ["ุญูู", "ุงุดุฑุญ", "ูุณุฑ", "ูุงุฑู", "ุงุฑุจุท"]
}

# --- 3. ุชุญููู ุงูููุงุฑุฏ ูุน ุฅุฏุงุฑุฉ ุฃูุถู ููุฃุฎุทุงุก ---
@st.cache_resource
def load_resources():
    """ุชุญููู ูุงุนุฏุฉ ุงููุชุฌูุงุช ููููุฐุฌ ุงูุชุถููู ูุน ูุนุงูุฌุฉ ุฃูุถู ููุฃุฎุทุงุก."""
    try:
        from sentence_transformers import SentenceTransformer
    except ImportError:
        st.error("โ ููุชุจุฉ sentence-transformers ุบูุฑ ูุชููุฑุฉ")
        return None, None, None

    vector_db_path = "vector_db.pkl"
    metadata_path = "vector_metadata.json"
    embedding_model_name = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"
    
    # ุชุญููู ูุงุนุฏุฉ ุงููุชุฌูุงุช
    vector_db = None
    metadata = {}
    
    if os.path.exists(vector_db_path):
        try:
            with open(vector_db_path, "rb") as f:
                vector_db = pickle.load(f)
        except Exception as e:
            st.error(f"ุฎุทุฃ ูู ุชุญููู ูุงุนุฏุฉ ุงููุชุฌูุงุช: {e}")
    
    # ุชุญููู ุงูุจูุงูุงุช ุงููุตููุฉ
    if os.path.exists(metadata_path):
        try:
            with open(metadata_path, "r", encoding="utf-8") as f:
                metadata = json.load(f)
        except Exception as e:
            st.warning(f"ูู ูุชู ุชุญููู ุงูุจูุงูุงุช ุงููุตููุฉ: {e}")
    
    # ุชุญููู ูููุฐุฌ ุงูุชุถููู
    try:
        embedder = SentenceTransformer(embedding_model_name)
    except Exception as e:
        st.error(f"ูุดู ุชุญููู ูููุฐุฌ ุงูุชุถููู: {e}")
        return None, None, None
    
    return vector_db, embedder, metadata

# --- 4. ุฅุนุฏุงุฏ ูููุฐุฌ Gemini ุงููุญุณูู ---
@st.cache_resource
def initialize_gemini():
    """ุชููุฆุฉ ูููุฐุฌ Gemini ูุน ุฅุนุฏุงุฏุงุช ูุญุณููุฉ."""
    if "GEMINI_API_KEY" not in st.secrets:
        return None
    
    try:
        genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
        model = genai.GenerativeModel(
            'gemini-1.5-flash',
            generation_config={
                "temperature": 0.1,  # ุฃูู ุนุดูุงุฆูุฉ ููุฏูุฉ ุงูุนูููุฉ
                "max_output_tokens": 3000,
                "top_p": 0.8,
                "top_k": 40
            }
        )
        return model
    except Exception as e:
        st.error(f"ูุดู ุชููุฆุฉ Gemini: {e}")
        return None

# ุชุญููู ุงูููุงุฑุฏ
vector_db, embedder, metadata = load_resources()
model = initialize_gemini()

# --- 5. ูุธุงุฆู ุงูุจุญุซ ุงููุชูุฏูุฉ ---
def classify_question(query: str) -> str:
    """ุชุตููู ุงูุณุคุงู ุญุณุจ ุงูููุน ูุชุญุณูู ุงุณุชุฑุงุชูุฌูุฉ ุงูุจุญุซ."""
    query_lower = query.lower()
    
    for category, keywords in QUESTION_CATEGORIES.items():
        if any(keyword in query_lower for keyword in keywords):
            return category
    
    return "general"

def search_knowledge_advanced(query: str, category: str = "general", top_k: int = 5) -> List[Dict]:
    """ุจุญุซ ูุชูุฏู ูุน ุชุตููู ุฐูู ูููุชุงุฆุฌ."""
    if not vector_db or not embedder:
        return []
    
    index = vector_db["index"]
    chunks = vector_db["chunks"]
    
    # ุชุญุณูู ุงูุงุณุชุนูุงู ุญุณุจ ุงููุฆุฉ
    enhanced_query = enhance_query_by_category(query, category)
    
    # ุชุญููู ุงูุณุคุงู ุฅูู ูุชุฌู
    query_embedding = embedder.encode([enhanced_query])
    
    # ุงูุจุญุซ ูู FAISS ูุน ุงููุฒูุฏ ูู ุงููุชุงุฆุฌ ููููุชุฑุฉ
    search_k = min(top_k * 2, len(chunks))
    distances, indices = index.search(np.array(query_embedding, dtype=np.float32), search_k)
    
    # ุฅูุดุงุก ูุชุงุฆุฌ ูุน ุฏุฑุฌุงุช ุงูุตูุฉ
    results = []
    for i, (dist, idx) in enumerate(zip(distances[0], indices[0])):
        if idx < len(chunks):
            results.append({
                "content": chunks[idx],
                "relevance_score": 1 / (1 + dist),  # ุชุญููู ุงููุณุงูุฉ ุฅูู ุฏุฑุฌุฉ ุตูุฉ
                "rank": i + 1,
                "source_info": metadata.get(str(idx), {})
            })
    
    # ููุชุฑุฉ ูุชุฑุชูุจ ุงููุชุงุฆุฌ
    results = filter_and_rank_results(results, query, category)
    
    return results[:top_k]

def enhance_query_by_category(query: str, category: str) -> str:
    """ุชุญุณูู ุงูุงุณุชุนูุงู ุจูุงุกู ุนูู ูุฆุฉ ุงูุณุคุงู."""
    enhancements = {
        "genetic_inheritance": f"{query} ูุฑุงุซุฉ ุฌููุงุช",
        "breeding": f"{query} ุชุฑุจูุฉ ุชุฒุงูุฌ",
        "colors": f"{query} ุฃููุงู ูุฑุงุซุฉ",
        "diseases": f"{query} ุฃูุฑุงุถ ุนูุงุฌ",
        "analysis": f"{query} ุชุญููู ุดุฑุญ"
    }
    
    return enhancements.get(category, query)

def filter_and_rank_results(results: List[Dict], query: str, category: str) -> List[Dict]:
    """ููุชุฑุฉ ูุชุฑุชูุจ ุงููุชุงุฆุฌ ุจูุงุกู ุนูู ูุนุงููุฑ ูุชูุฏูุฉ."""
    # ุญุณุงุจ ุฏุฑุฌุฉ ุฅุถุงููุฉ ุจูุงุกู ุนูู ุชุทุงุจู ุงููููุงุช ุงูููุชุงุญูุฉ
    query_words = set(query.lower().split())
    
    for result in results:
        content_words = set(result["content"].lower().split())
        word_overlap = len(query_words.intersection(content_words))
        result["keyword_score"] = word_overlap / len(query_words) if query_words else 0
        
        # ุฏุฑุฌุฉ ูุฑูุจุฉ
        result["final_score"] = (
            result["relevance_score"] * 0.7 + 
            result["keyword_score"] * 0.3
        )
    
    # ุชุฑุชูุจ ุญุณุจ ุงูุฏุฑุฌุฉ ุงููุฑูุจุฉ
    return sorted(results, key=lambda x: x["final_score"], reverse=True)

# --- 6. ูููู ุงูุฅุฌุงุจุฉ ุงููุชูุฏู ---
def advanced_research_agent(query: str) -> Dict:
    """ูููู ุจุญุซู ูุชูุฏู ูุน ุชุญููู ุดุงูู."""
    if not model:
        return {
            "answer": "โ ุงููุธุงู ุบูุฑ ูููุฃ (API KEY ููููุฏ ุฃู ุบูุฑ ุตุงูุญ).",
            "confidence": 0,
            "sources": [],
            "category": "error"
        }

    # ูุนุงูุฌุฉ ุงูุชุญูุงุช ุงูุจุณูุทุฉ
    q_lower = query.lower().strip()
    if any(word in q_lower for word in ["ุณูุงู", "ูุฑุญุจุง", "ุงููุง", "ูุงู", "ุดูุฑุง"]):
        return {
            "answer": "๐ค ูุนูููู ุงูุณูุงู ููุฑุญุจุงู ุจู! ุฃูุง ุงูุนุฑูุงุจ ุงูุจุญุซู ุงููุญุณููุ ุฌุงูุฒ ููุฅุฌุงุจุฉ ุนูู ุฌููุน ุฃุณุฆูุชู ุญูู ุนูู ูุฑุงุซุฉ ุงูุญูุงู ุจุฃุณููุจ ุนููู ูุชูุฏู.",
            "confidence": 1.0,
            "sources": [],
            "category": "greeting"
        }

    # ุชุตููู ุงูุณุคุงู
    category = classify_question(query)
    
    # ุงูุจุญุซ ุงููุชูุฏู
    with st.spinner("๐ฌ ุฌุงุฑู ุงูุจุญุซ ุงููุชูุฏู ูู ูุงุนุฏุฉ ุงููุนุฑูุฉ..."):
        search_results = search_knowledge_advanced(query, category, top_k=7)
    
    if not search_results:
        return {
            "answer": "๐ค ูู ุฃุฌุฏ ูุนูููุงุช ูุจุงุดุฑุฉ ูุชุนููุฉ ุจูุฐุง ุงูุณุคุงู ูู ูุงุนุฏุฉ ุงููุนุฑูุฉ ุงูุญุงููุฉ. ุฌุฑุจ ุฅุนุงุฏุฉ ุตูุงุบุฉ ุงูุณุคุงู ุฃู ุงุณุชุฎุฏุงู ูุตุทูุญุงุช ุฃุฎุฑู.",
            "confidence": 0,
            "sources": [],
            "category": category
        }

    # ุจูุงุก ุงูุณูุงู ูุน ุฏุฑุฌุงุช ุงูุตูุฉ
    context_parts = []
    source_info = []
    
    for i, result in enumerate(search_results):
        context_parts.append(f"[ูุฑุฌุน {i+1} - ุฏุฑุฌุฉ ุงูุตูุฉ: {result['final_score']:.2f}]\n{result['content']}")
        source_info.append({
            "rank": i+1,
            "score": result['final_score'],
            "content_preview": result['content'][:100] + "..."
        })
    
    context_text = "\n\n" + "="*50 + "\n\n".join(context_parts)

    # ุจูุงุก ุงูุจุฑููุจุช ุงููุชูุฏู
    prompt = create_advanced_prompt(query, context_text, category)
    
    # ุชูููุฏ ุงูุฅุฌุงุจุฉ
    with st.spinner("๐ง ุฌุงุฑู ุชุญููู ุงููุนูููุงุช ูุตูุงุบุฉ ุงูุฅุฌุงุจุฉ ุงููุชุฎุตุตุฉ..."):
        try:
            response = model.generate_content(prompt)
            answer = response.text
            
            # ุชูุฏูุฑ ูุณุชูู ุงูุซูุฉ
            confidence = estimate_confidence(search_results, answer)
            
            return {
                "answer": answer,
                "confidence": confidence,
                "sources": source_info,
                "category": category,
                "search_results": search_results
            }
            
        except Exception as e:
            return {
                "answer": f"โ ุญุฏุซ ุฎุทุฃ ูู ุชูููุฏ ุงูุฅุฌุงุจุฉ: {str(e)}",
                "confidence": 0,
                "sources": source_info,
                "category": category
            }

def create_advanced_prompt(query: str, context: str, category: str) -> str:
    """ุฅูุดุงุก ุจุฑููุจุช ูุชูุฏู ุญุณุจ ูุฆุฉ ุงูุณุคุงู."""
    
    base_prompt = f"""
ุฃูุช "ุงูุนุฑูุงุจ ุงูุฐูู V2.0"ุ ุฎุจูุฑ ุนุงููู ูู ุนูู ูุฑุงุซุฉ ุงูุญูุงู ูุชุฑุจูุชูุ ูุฒูุฏ ุจูุฏุฑุงุช ุชุญููููุฉ ูุชูุฏูุฉ.

**ูุฆุฉ ุงูุณุคุงู ุงููุญุฏุฏุฉ:** {category}
**ุงูุณุคุงู:** {query}

**ุงููุฑุงุฌุน ุงูุนูููุฉ ุงููุฑุชุจุฉ ุญุณุจ ุงูุตูุฉ:**
{context}

**ููุงูู ุงููุชุฎุตุตุฉ:**

1. **ุงูุชุญููู ุงูุนููู ุงูุฏููู:** ูุฏู ุฅุฌุงุจุฉ ุนูููุฉ ุดุงููุฉ ููุฏุนููุฉ ุจุงูุฃุฏูุฉ ูู ุงููุฑุงุฌุน
2. **ุงูุชุตููู ูุงูุชูุธูู:** ุฑุชุจ ุงููุนูููุงุช ุจุดูู ููุทูู ูุน ุนูุงููู ูุงุถุญุฉ
3. **ุงูุฑุจุท ูุงูุงุณุชูุชุงุฌ:** ุงุฑุจุท ุงูููุงููู ุงููุฎุชููุฉ ููุฏู ุงุณุชูุชุงุฌุงุช ููุทููุฉ
4. **ุงูุชุทุจูู ุงูุนููู:** ุงุฐูุฑ ุงูุชุทุจููุงุช ุงูุนูููุฉ ุนูุฏ ุงูุฅููุงู

**ูุนุงููุฑ ุงูุฌูุฏุฉ:**
โ ุงุณุชุฎุฏู ุงููุนูููุงุช ูู ุงููุฑุงุฌุน ุญุตุฑูุงู
โ ุฃุณููุจ ุนููู ูุงุถุญ ูููุธู
โ ุชุฏุฑุฌ ูู ุงูุนุงู ุฅูู ุงูุชูุตููู
โ ุฃูุซูุฉ ุนูููุฉ ุนูุฏ ุงูุญุงุฌุฉ
โ ุงุฐูุฑ ุฃู ูููุฏ ูู ุงููุนูููุงุช ุงููุชุงุญุฉ

**ุชูุณูู ุงูุฅุฌุงุจุฉ ุงููุทููุจ:**
ุงุณุชุฎุฏู ุงูุนูุงููู (##) ูุงูููุงุท ูุงูุฌุฏุงูู ุนูุฏ ุงูุญุงุฌุฉ ูุชุญุณูู ุงููุงุจููุฉ ูููุฑุงุกุฉ.
"""

    # ุชุฎุตูุตุงุช ุฅุถุงููุฉ ุญุณุจ ุงููุฆุฉ
    category_specific = {
        "genetic_inheritance": "\n**ุชุฑููุฒ ุฎุงุต:** ุงุดุฑุญ ุขููุงุช ุงููุฑุงุซุฉ ูุงูุฌููุงุช ุจุงูุชูุตูู ูุน ุงูุฃูุซูุฉ.",
        "breeding": "\n**ุชุฑููุฒ ุฎุงุต:** ุฑูุฒ ุนูู ุงูุฌูุงูุจ ุงูุนูููุฉ ููุชุฑุจูุฉ ูุงูุชุฒุงูุฌ ูุงูุงูุชูุงุก.",
        "colors": "\n**ุชุฑููุฒ ุฎุงุต:** ูุตู ูุฑุงุซุฉ ุงูุฃููุงู ูุงูุทูุฑุงุช ุงูููููุฉ ุจุดูู ููุตู.",
        "diseases": "\n**ุชุฑููุฒ ุฎุงุต:** ุงุดุฑุญ ุงูุฃูุฑุงุถ ูุฃุณุงููุจ ุงูููุงูุฉ ูุงูุนูุงุฌ.",
        "analysis": "\n**ุชุฑููุฒ ุฎุงุต:** ูุฏู ุชุญูููุงู ุนูููุงู ูููุงุฑูุงุช ูุชูุณูุฑุงุช ุดุงููุฉ."
    }
    
    return base_prompt + category_specific.get(category, "")

def estimate_confidence(search_results: List[Dict], answer: str) -> float:
    """ุชูุฏูุฑ ูุณุชูู ุงูุซูุฉ ูู ุงูุฅุฌุงุจุฉ."""
    if not search_results:
        return 0.0
    
    # ุนูุงูู ุงูุซูุฉ
    avg_relevance = np.mean([r['final_score'] for r in search_results])
    num_sources = len(search_results)
    answer_length = len(answer.split())
    
    # ุญุณุงุจ ุฏุฑุฌุฉ ุงูุซูุฉ
    confidence = (
        avg_relevance * 0.5 +
        min(num_sources / 5, 1.0) * 0.3 +
        min(answer_length / 200, 1.0) * 0.2
    )
    
    return min(confidence, 1.0)

# --- 7. ูุงุฌูุฉ ุงููุณุชุฎุฏู ุงููุญุณููุฉ ---
def main():
    # ุงูุนููุงู ุงูุฑุฆูุณู
    st.markdown("""
    # ๐ ุงูุนุฑูุงุจ ููุฌููุงุช V2.0
    ## ูููู ุจุญุซู ุฐูู ูุชูุฏู ูุนูู ูุฑุงุซุฉ ุงูุญูุงู
    ---
    """)

    # ุงูุดุฑูุท ุงูุฌุงูุจู ุงููุญุณูู
    create_enhanced_sidebar()
    
    # ุงููุณู ุงูุฑุฆูุณู ูููุญุงุฏุซุฉ
    create_chat_interface()
    
    # ุฅุญุตุงุฆูุงุช ูุชุญูููุงุช
    if st.checkbox("๐ ุนุฑุถ ุฅุญุตุงุฆูุงุช ุงูุฌูุณุฉ"):
        show_session_statistics()

def create_enhanced_sidebar():
    """ุฅูุดุงุก ุดุฑูุท ุฌุงูุจู ูุญุณูู ูุน ูุนูููุงุช ุชูุตูููุฉ."""
    st.sidebar.markdown("## ๐ ุญุงูุฉ ุงููุธุงู ุงููุชูุฏูุฉ")
    
    # ุญุงูุฉ ูุงุนุฏุฉ ุงููุนุฑูุฉ
    if vector_db and embedder:
        st.sidebar.success("โ ูุงุนุฏุฉ ุงููุนุฑูุฉ ุฌุงูุฒุฉ")
        
        col1, col2 = st.sidebar.columns(2)
        with col1:
            st.metric("๐ง ููุงุทุน ูุนุฑููุฉ", len(vector_db['chunks']))
        with col2:
            st.metric("๐ ุงูุจูุงูุงุช ุงููุตููุฉ", len(metadata) if metadata else 0)
            
        # ูุนูููุงุช ุฅุถุงููุฉ
        if metadata:
            st.sidebar.info(f"๐ ุขุฎุฑ ุชุญุฏูุซ: {metadata.get('last_updated', 'ุบูุฑ ูุญุฏุฏ')}")
            
    else:
        st.sidebar.error("โ ูุงุนุฏุฉ ุงููุนุฑูุฉ ุบูุฑ ูุชููุฑุฉ")
    
    # ุญุงูุฉ ุงููููุฐุฌ
    if model:
        st.sidebar.success("โ ุงููุณุงุนุฏ ุงูุฐูู ุฌุงูุฒ")
        st.sidebar.info("๐ค ุงููููุฐุฌ: Gemini 1.5 Flash")
    else:
        st.sidebar.error("โ ุงููุณุงุนุฏ ุงูุฐูู ุบูุฑ ูุชุงุญ")
    
    # ุฅุนุฏุงุฏุงุช ุงูุจุญุซ
    st.sidebar.markdown("## โ๏ธ ุฅุนุฏุงุฏุงุช ุงูุจุญุซ")
    search_depth = st.sidebar.slider("ุนูู ุงูุจุญุซ", 3, 10, 5)
    show_sources = st.sidebar.checkbox("ุนุฑุถ ุงููุตุงุฏุฑ", True)
    show_confidence = st.sidebar.checkbox("ุนุฑุถ ูุณุชูู ุงูุซูุฉ", True)
    
    return {"search_depth": search_depth, "show_sources": show_sources, "show_confidence": show_confidence}

def create_chat_interface():
    """ุฅูุดุงุก ูุงุฌูุฉ ุงููุญุงุฏุซุฉ ุงููุญุณููุฉ."""
    st.markdown("### ๐ฌ ูุญุงุฏุซุฉ ุฐููุฉ ูุน ุงูุนุฑูุงุจ")
    
    # ุชููุฆุฉ ุงูุฌูุณุฉ
    if "messages" not in st.session_state:
        st.session_state.messages = []
    if "session_stats" not in st.session_state:
        st.session_state.session_stats = {
            "questions_asked": 0,
            "categories_used": set(),
            "avg_confidence": 0.0,
            "start_time": datetime.now()
        }

    # ุนุฑุถ ุงููุญุงุฏุซุงุช ุงูุณุงุจูุฉ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            if message["role"] == "assistant" and "metadata" in message:
                display_enhanced_response(message["content"], message["metadata"])
            else:
                st.markdown(message["content"])

    # ุฅุฏุฎุงู ุงูุณุคุงู ุงูุฌุฏูุฏ
    if prompt := st.chat_input("๐งฌ ุงุณุฃููู ุฃู ุดูุก ุนู ูุฑุงุซุฉ ุงูุญูุงู..."):
        # ุฅุถุงูุฉ ุณุคุงู ุงููุณุชุฎุฏู
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        with st.chat_message("user"):
            st.markdown(prompt)

        # ุฅูุดุงุก ุงูุฅุฌุงุจุฉ
        with st.chat_message("assistant"):
            response_data = advanced_research_agent(prompt)
            
            # ุนุฑุถ ุงูุฅุฌุงุจุฉ ุงููุญุณููุฉ
            display_enhanced_response(response_data["answer"], response_data)
            
            # ุญูุธ ุงูุฅุฌุงุจุฉ ูุน ุงูุจูุงูุงุช ุงููุตููุฉ
            st.session_state.messages.append({
                "role": "assistant", 
                "content": response_data["answer"],
                "metadata": response_data
            })
            
            # ุชุญุฏูุซ ุงูุฅุญุตุงุฆูุงุช
            update_session_stats(response_data)

def display_enhanced_response(answer: str, metadata: dict):
    """ุนุฑุถ ุงูุฅุฌุงุจุฉ ูุน ุงููุนูููุงุช ุงูุฅุถุงููุฉ."""
    # ุงูุฅุฌุงุจุฉ ุงูุฑุฆูุณูุฉ
    st.markdown(answer)
    
    # ูุนูููุงุช ุฅุถุงููุฉ
    if metadata.get("confidence", 0) > 0:
        # ุดุฑูุท ุงูุซูุฉ
        confidence = metadata["confidence"]
        confidence_color = "green" if confidence > 0.7 else "orange" if confidence > 0.4 else "red"
        
        st.markdown(f"""
        <div style="margin: 10px 0;">
            <strong>๐ฏ ูุณุชูู ุงูุซูุฉ:</strong>
            <div style="background-color: #f0f0f0; border-radius: 10px; padding: 5px;">
                <div style="background-color: {confidence_color}; width: {confidence*100}%; height: 20px; border-radius: 10px; text-align: center; color: white; line-height: 20px;">
                    {confidence:.1%}
                </div>
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        # ูุนูููุงุช ุงููุตุงุฏุฑ
        if metadata.get("sources") and len(metadata["sources"]) > 0:
            with st.expander(f"๐ ุงููุตุงุฏุฑ ุงููุณุชุฎุฏูุฉ ({len(metadata['sources'])})"):
                for i, source in enumerate(metadata["sources"]):
                    st.markdown(f"""
                    **ูุตุฏุฑ {source['rank']}** (ุฏุฑุฌุฉ ุงูุตูุฉ: {source['score']:.2f})
                    {source['content_preview']}
                    """)

def update_session_stats(response_data: dict):
    """ุชุญุฏูุซ ุฅุญุตุงุฆูุงุช ุงูุฌูุณุฉ."""
    stats = st.session_state.session_stats
    stats["questions_asked"] += 1
    stats["categories_used"].add(response_data.get("category", "unknown"))
    
    if response_data.get("confidence", 0) > 0:
        # ุชุญุฏูุซ ูุชูุณุท ุงูุซูุฉ
        current_avg = stats["avg_confidence"]
        new_avg = (current_avg * (stats["questions_asked"] - 1) + response_data["confidence"]) / stats["questions_asked"]
        stats["avg_confidence"] = new_avg

def show_session_statistics():
    """ุนุฑุถ ุฅุญุตุงุฆูุงุช ุงูุฌูุณุฉ."""
    stats = st.session_state.session_stats
    
    st.markdown("### ๐ ุฅุญุตุงุฆูุงุช ุงูุฌูุณุฉ ุงูุญุงููุฉ")
    
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("๐ค ุงูุฃุณุฆูุฉ ุงููุทุฑูุญุฉ", stats["questions_asked"])
    
    with col2:
        st.metric("๐ฏ ูุชูุณุท ุงูุซูุฉ", f"{stats['avg_confidence']:.1%}")
    
    with col3:
        st.metric("๐ ุงููุฆุงุช ุงููุณุชุฎุฏูุฉ", len(stats["categories_used"]))
    
    with col4:
        duration = datetime.now() - stats["start_time"]
        st.metric("โฑ๏ธ ูุฏุฉ ุงูุฌูุณุฉ", f"{duration.seconds//60} ุฏูููุฉ")
    
    # ุฑุณู ุจูุงูู ูููุฆุงุช
    if len(stats["categories_used"]) > 0:
        categories_list = list(stats["categories_used"])
        fig = px.pie(
            values=[1] * len(categories_list), 
            names=categories_list,
            title="ุชูุฒูุน ูุฆุงุช ุงูุฃุณุฆูุฉ"
        )
        st.plotly_chart(fig, use_container_width=True)

# --- 8. ุชุดุบูู ุงูุชุทุจูู ---
if __name__ == "__main__":
    main()

# --- ููุฒุงุช ุฅุถุงููุฉ ูููู ุชุทููุฑูุง ---
"""
๐ ุฃููุงุฑ ููุชุทููุฑ ุงููุณุชูุจูู:

1. **ุฐุงูุฑุฉ ุงููุญุงุฏุซุฉ ุงูุฐููุฉ**: ุญูุธ ุงูุณูุงู ุนุจุฑ ุงูุฃุณุฆูุฉ ุงููุชุชุงููุฉ
2. **ุชุตุฏูุฑ ุงูุชูุงุฑูุฑ**: ุฅูุดุงุก ุชูุงุฑูุฑ PDF ููุงุณุชุดุงุฑุงุช
3. **ุงูุจุญุซ ุงูุตูุชู**: ุฅุถุงูุฉ ุฅููุงููุฉ ุงูุจุญุซ ุงูุตูุชู
4. **ุงูุชุฑุฌูุฉ ุงูุชููุงุฆูุฉ**: ุฏุนู ูุบุงุช ูุชุนุฏุฏุฉ
5. **ุงูุชูุงูู ูุน ููุงุนุฏ ุจูุงูุงุช ุฎุงุฑุฌูุฉ**: ุฑุจุท ูุน ูุตุงุฏุฑ ุนูููุฉ ุฅุถุงููุฉ
6. **ูุธุงู ุงูุชูููู**: ุชูููู ุฌูุฏุฉ ุงูุฅุฌุงุจุงุช ูู ุงููุณุชุฎุฏููู
7. **ูุถุน ุงูุฎุจูุฑ**: ูุงุฌูุฉ ูุชูุฏูุฉ ููุจุงุญุซูู
8. **ุงูุฅุดุนุงุฑุงุช ุงูุฐููุฉ**: ุชูุจููุงุช ุนู ูุญุชูู ุฌุฏูุฏ
"""
